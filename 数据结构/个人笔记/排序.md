# 排序

## 堆排序

这里以大根堆为例，根为$A_1$，$A_{2i},A_{2i+1}$是左右儿子，且当前堆大小为$N$。

每次$DeleteMax$，我们会删去堆中的尾节点（数据从大到小删除），但是在堆数组中多出来了一个位置，我们可以将其用于存储删去的元素。

![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202411052039134.webp)

![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202411052040563.webp)

![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202411052040850.webp)

![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202411052040236.webp)

**分析**：

时间复杂度：

- 建堆：$O(N)$。

- $N$个$DeleteMax$的时间为$O(NlogN)$。

- 总时间复杂度为$O(NlogN)$。

- 最坏情况是$O(NlogN)$，平均也是$O(NlogN)$

- 堆排序是一种不稳定的排序算法。

  > 堆排序（Heap Sort）是一种**不稳定排序算法**，这是因为在排序过程中，相同大小的元素的相对顺序可能会被改变。这主要与堆排序的核心操作（即**堆调整**）的特点有关。
  >
  > ### 1. 堆排序的过程
  >
  > 堆排序通常包括两个步骤：
  >
  > 1. **构建最大堆**（或最小堆）：将数组重新组织成一个堆的结构，以便可以快速找到最大（或最小）元素。
  > 2. **排序过程**：通过反复将堆顶元素（最大或最小值）移到数组的末尾，然后调整剩余的堆以保持堆的性质，直到排序完成。
  >
  > 在这过程中，堆调整操作可能会改变相同值元素的相对位置。
  >
  > ### 2. 堆调整导致不稳定性的原因
  >
  > 堆排序的核心在于堆调整（heapify）操作。堆调整的原理是通过比较和交换，使子树满足堆的性质。例如，在最大堆中，父节点总是大于等于子节点。
  >
  > 在堆调整过程中，如果存在两个相同的元素 $A$ 和 $B$ ，且 $A$ 在 $B$ 前面，堆调整可能会让 $B$ 上浮到 $A$ 的前面，从而导致它们的相对顺序发生变化。例如：
  >
  > - 假设有两个相同的元素位于不同的子树中，堆调整可能会将后面子树中的元素上浮到堆顶，这样当它们被放到数组中时，相对顺序会被打乱。
  >
  > ### 3. 具体示例
  >
  > 假设我们有数组 `[4, 1, 3, 4, 2]`。其中两个 `4` 是相同的元素。如果我们对其进行堆排序，最终得到的结果是 `[1, 2, 3, 4, 4]`，但在排序过程中，两个 `4` 的相对位置可能被改变，这取决于堆的调整过程。
  >
  > ### 4. 为什么堆排序不稳定
  >
  > 总结来说，堆排序不稳定的根本原因在于**堆的结构和调整过程**。堆是一个完全二叉树，在调整过程中会进行跨层的交换，导致相同元素的相对顺序无法保证。所以在堆排序中，相同元素的顺序可能会被打乱。



由分治法可以引出以下两种排序算法：

- 归并排序：将数组分成两半，对左右两半递归排序，然后合并两半。
- 快速排序：将数组划分为“小”项，和“大”的项目，然后递归地对两个集合进行排序 。



## 归并排序

- 在中点将其分成两部分。
- 每次解决一部分（通过递归解决）
- 合并两部分。

![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202411052102448.webp)

需要一个辅助数组进行合并，合并原理如下：

对两个部分进行逐个比较（采用双指针），比较小先加入到$array$中，直到左右数组中一个为空，非空数组中最后剩余的部分全部加入$array$中。

```cpp
void merge(std::vector<int>& arr, int left, int mid, int right) {
    int n1 = mid - left + 1;
    int n2 = right - mid;
    std::vector<int> L(n1), R(n2);
    for (int i = 0; i < n1; ++i) L[i] = arr[left + i];
    for (int i = 0; i < n2; ++i) R[i] = arr[mid + 1 + i];
    int i = 0, j = 0, k = left;
    while (i < n1 && j < n2) arr[k++] = (L[i] <= R[j]) ? L[i++] : R[j++];
    while (i < n1) arr[k++] = L[i++];
    while (j < n2) arr[k++] = R[j++];
}
```



归并排序如下：

```cpp
void mergeSort(std::vector<int>& arr, int left, int right) {
    if (left < right) {
        int mid = left + (right - left) / 2;
        mergeSort(arr, left, mid);
        mergeSort(arr, mid + 1, right);
        merge(arr, left, mid, right);
    }
}
```



书上的实现如下：

```cpp
/*
* Internal method that merges two sorted halves of a subarray
* a si an array of Comparabel items
* tmpArray is an array to place the merged result
* leftPos us the left-most index of the subarray
* rightPos is the index of the start of the second half
* rightEnd is the right-most index of the subarray
*/
template<typename Comparable>
void merge(vector<Comparable> &a, vector<Comparable> &tmpArray, int leftPos, int rightPos, int rightEnd)
{
	int leftEnd = rightPos - 1;
    int tmpPos = leftPos;
    int numElements = rightEnd - leftPos + 1;
    
    //Main Loop
    while(leftPos <= leftEnd && rightPos <= rightEnd)
    {
        if(a[leftPos] <= a[rightPos])
            tmpArray[tmpPos++] = std::move(a[leftPos++]);
        else
            tmpArray[tmpPos++] = std::move(a[rightPos++]);
    }
    
    while(leftPos <= leftEnd)
    {
        tmpArray[tmpPos++] = std::move(a[leftPos++]);
    }
    
    while(rightPos <= rightEnd)
    {
        tmpArray[tmpPos++] = std::move(a[rightPos++]);
    }
    
    for(int i = 0;i < numElements; i++, --rightEnd)
    {
        a[rightEnd] = std::move(tmpArray[rightEnd]);
    }
}
```



```cpp
/**
* Recursive implementation for Mergesort
**/
Mergesort(A[], T[] : integer array, left, right : integer) : {
  	if left < right then
    	mid := (left + right)/2;
    	Mergesort(A,T,left,mid);
    	Mergesort(A,T,mid+1,right);
    	Merge(A,T,left,right);
}

//Driver
MainMergesort(A[0..n-1]: integer array, n : integer) : {
  	T[0..n-1]: integer array;
  	Mergesort[A,T,0,n-1];
}
  

```



归并排序还有另外一种实现方法：在数组规模较小时，我们使用插入排序对数据进行排序。**并且可以不用判断两个子数组是否为空**。

```cpp
template <typename E, typename Comp>
void mergesort(E A[], E temp[], int left, int right) {
    if ((right-left) <= THRESHOLD) { //small list
        insertionsort<E,Comp>(&A[left], right-left+1);
        return;
    }
    int i, j, k, mid = (left+right)/2;
    if (left == right) return;
    mergesort<E, Comp>(A, temp, left, mid);
    mergesort<E, Comp>(A, temp, mid+1, right);
    //Do the merge operation. First copy two halves to temp
    for (i=mid; i>=left; i--) temp[i] = A[i];
    for (j=1; j<=right-mid; j++) temp[right-j+1] = A[j+mid];
    //Merge sublists back to A
    for (i=left, j=right, k=left; k<=right; k++)
        if (Comp::prior(temp[i], temp[j])) A[k] = temp[i++];
        else A[k] = temp[j--];
}
```

![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202411091140323.webp)



**时间复杂度分析**

> 归并排序的时间复杂度分析基于其**分治法**的递归特性。归并排序的过程分为两个主要步骤：**分解**和**合并**。
>
> ### 1. 归并排序的过程
>
> 1. **分解**：将待排序数组分成两半，递归地对每一半进行排序。
> 2. **合并**：将两个已排序的子数组合并成一个有序的数组。
>
> 归并排序的递归分解过程可以描述为对每个数组不断分割，直到分解为单个元素（递归的基准情况）。接下来，从底向上将这些单个元素逐步合并回去，最终得到完整的有序数组。
>
> ### 2. 时间复杂度分析
>
> 假设数组的长度为 $ n $，我们用 $ T(n) $ 表示归并排序对长度为 $ n $ 的数组的运行时间。可以将 $ T(n) $ 分解为分解步骤和合并步骤的时间之和：
>
> 1. **分解步骤**：每次将数组分成两半，需要 $ O(1) $ 的时间，只是确定分割点而已。
> 2. **合并步骤**：对每一级的分割子数组进行合并。假设当前有 $ k $ 个元素在合并，则合并的时间为 $ O(k) $。
>
> 归并排序的时间复杂度的递归关系可以表示为：
>
> $$
> T(n) = 2T\left(\frac{n}{2}\right) + O(n)
> $$
> 其中，$ 2T(n/2) $ 表示对两部分递归地进行排序，$ O(n) $ 是将两部分合并所需的时间。
>
> ### 3. 递归关系的解
>
> 要解这个递归式，可以使用**主定理**。主定理适用于形如 $ T(n) = aT(n/b) + O(n^d) $ 的递归关系式，其中 $ a = 2 $，$ b = 2 $，并且 $ d = 1 $。
>
> 根据主定理，当 $ n^d = n^{\log_b a} $ 时，时间复杂度为 $ O(n^d \log n) $。在归并排序中：
>
> $$
> n^d = n^{\log_b a} = n^{\log_2 2} = n^1 = n
> $$
> 因此，时间复杂度为：
>
> $$
> T(n) = O(n \log n)
> $$
> 具体的推导方式如下：
>
> ![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202411091145991.webp)
>
> ### 4. 总结
>
> 归并排序在最优、最坏和平均情况下的时间复杂度都是 $ O(n \log n) $，因为每次都将数组分成两部分，并且在每一级递归上都需要 $ O(n) $ 的时间进行合并。这也是归并排序效率较高的原因之一。
>
> ### 5. 空间复杂度
>
> 归并排序需要额外的数组空间来存放合并结果，因此其空间复杂度为 $ O(n) $。



## 快速排序

快速排序采用分治法，类似归并排序，但是不需要$O(n)$的额外空间。

**步骤**：

- 将数组划分为**左右子数组**
- 选择数组中的**一个元素，作为枢纽元素**
- 左数组中的元素均小于枢纽元素，右数组中的元素均大于枢纽元素。
- 递归排序处理左右子数组
- $O(1)$时间内连接左右子数组

具体如下：

1. 如果$S$中的**元素个数**小于或者等于1，则返回，数组已排好序。
2. 在$S$中选定一个元素$v$，作为枢纽值。
3. 将$S-\{ v\}$划分为两个不相交部分$S_1,S_2$，其中$S_1$中的元素都小于$v$，$S_2$中的元素都大于$v$。
4. 快速排序$S_1$，$S_2$。



**关键在于如何选择枢纽元**：

我们希望选择的枢纽元可以使得$S_1,S_2$的大小尽可能相等，并且都是非空的。

- 使用第一个位置的值？如果输入已排序或反向排序，则分区效果不佳。
- 在随机位置选取一个值？使用随机数生成器的成本很高
- 选择数组中间位置的值？$\frac{left+right}{2}$。
- 数组的中位数？**Median-of-Three：选择左侧、右侧和中心元素三者中的中位数作为枢纽元**



此外还需要考虑如何分区：使得元素分配到合适的区域。

**分区策略**：常见的有2路分区，3路分区等，这里讨论2路分区。

2路分区：

需要先把枢纽元放在$A_{N-1}$。

- 将指针` i `和` j `设置为数组的开头和结尾。
- 增加` i `直到到达元素` A[i] > ` 枢轴元。
- 递减` j `直到找到元素` A[j] < ` 枢轴元。
- 交换$A_i$与$A_j$，直到$A_i$与$A_j$交叉
- 将$A_i$与$A_{N-1}$交换。



具体的演示过程如下：

![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202411091225121.webp)

![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202411091224805.webp)

![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202411091224098.webp)



实现代码：

```cpp
//有点像选择排序，利用双指针，将比pivot小的元素不断前移，i维护的对应小于pivot元素的最大下标，i+1对应的元素就是大于pivot
//最后将(i+1, high)进行交换即可
int partition(std::vector<int>& arr, int low, int high) {
    int pivot = arr[high];
    int i = low - 1;
    for (int j = low; j < high; ++j) {
        if (arr[j] <= pivot) {
            std::swap(arr[++i], arr[j]);
        }
    }
    std::swap(arr[i + 1], arr[high]);
    return i + 1;
}

void quickSort(std::vector<int>& arr, int low, int high) {
    if (low < high) {
        int pi = partition(arr, low, high);
        quickSort(arr, low, pi - 1);
        quickSort(arr, pi + 1, high);
    }
}
```

`ppt`版本：

```cpp
//QuickSort
template <typename E, typename Comp>
void quickSort(E A[], int i, int j) {
    if (j <= i) return; //List with 0 or 1 element
    int pivotindex = findpivot(A, i, j); //get pivot
    swap(A, pivotindex, j); //Put pivot at end
    
    //k will be the 1st position on right side
    int k = partition<E,Comp>(A, i, j-1, A[j]);
    swap(A, k, j); // Put pivot in place
    
    quickSort<E,Comp>(A, i, k-1); //Recursively
    quickSort<E,Comp>(A, k+1, j);
}

template <typename E, typename Comp>
int partition(E A[], int l, int r, E& pivot) {
    do {
        //Move the bounds inward until they meet
        //Move l right and r left
        while (Comp::prior(A[++l], pivot));
        while ((l<r) && Comp::prior(A[--r],pivot));
        // Swap out-of-place values
        swap(A, l, r);
    } while (l < r); // Stop when they cross
    
    //联系我们上面说的模拟过程，l > r,多执行了一次交换，所以要交换回来。
    swap(A, l, r); // Reverse last swap[最后一次交换是多余的]
    return l; //Return 1st position in right part
}
```





**优化**：

- 小数组时（范围是10）：使用插入排序。
- 减少递归调用。



时间复杂度分析：

> 快速排序的时间复杂度分析依赖于其**分治法**的特点。快速排序通过选定一个**基准元素**（pivot），将数组划分为小于基准和大于基准的两个子数组，然后递归地对这两个子数组进行排序。
>
> ### 1. 快速排序的过程
>
> 1. **选定基准**：从数组中选一个元素作为基准（可以是第一个元素、最后一个元素、随机元素或中间元素）。
> 2. **划分**：将数组重新排序，使得所有小于基准的元素放在基准的左侧，所有大于基准的元素放在基准的右侧。
> 3. **递归**：对左右两个子数组递归执行快速排序。
>
> ### 2. 时间复杂度分析
>
> 快速排序的时间复杂度与划分是否均匀密切相关。以下分析了最佳情况、平均情况和最坏情况的时间复杂度。
>
> #### 2.1 最佳情况：$ O(n \log n) $
>
> 在**最佳情况下**，每次划分都将数组平分，即将数组分成大约相等的两部分。这种情况的时间复杂度可以描述为递归式：
>
> $$
> T(n) = 2T\left(\frac{n}{2}\right) + O(n)
> $$
> 
>
> 其中，$ 2T(n/2) $ 表示对两部分进行递归排序，$ O(n) $ 是每次划分数组的开销。根据递归公式的主定理，当划分均匀时，这个递归式的解为：
>
> $$
> T(n) = O(n \log n)
> $$
> 
>
> 因此，在最佳情况下，快速排序的时间复杂度为 $ O(n \log n) $。
>
> #### 2.2 平均情况：$ O(n \log n) $
>
> 在**平均情况下**，快速排序的每次划分不会总是完美平衡，但总体上接近均匀分割。平均情况下的时间复杂度仍然满足类似于最佳情况的递归公式，因此平均时间复杂度为：
>
> $$
> T(n) = O(n \log n)
> $$
> 这也是快速排序的通常表现，即**期望时间复杂度**。
>
> #### 2.3 最坏情况：$ O(n^2) $
>
> 在**最坏情况下**，每次划分都导致一个子数组只有一个元素，另一个子数组包含剩余的元素。例如，如果数组已经有序（升序或降序），且总是选取数组的第一个或最后一个元素作为基准，那么快速排序在每次划分时都会出现这种极端情况。递归公式在这种情况下为：
>
> $$
> T(n) = T(n - 1) + O(n)
> $$
> 展开递归式可以得到：
>
> $$
> T(n) = T(n - 1) + n = T(n - 2) + (n - 1) + n = \cdots = O\left(\frac{n(n + 1)}{2}\right) = O(n^2)
> $$
> 因此，在最坏情况下，快速排序的时间复杂度为 $ O(n^2) $。
>
> ### 3. 优化方法
>
> 为了避免最坏情况，可以采用一些优化策略，如：
>
> 1. **随机选取基准**：随机选择基准可以避免在某些特殊输入下总是出现不平衡的划分。
> 2. **三数取中法**：从数组的第一个元素、最后一个元素和中间元素中选取中值作为基准，这样可以提高划分的平衡性。
> 3. **混合排序**：在数组规模较小时使用插入排序等其他排序算法，因其在小规模数组上通常表现更优。
>
> ### 4. 总结
>
> | 情况     | 时间复杂度      |
> | -------- | --------------- |
> | 最佳情况 | $ O(n \log n) $ |
> | 平均情况 | $ O(n \log n) $ |
> | 最坏情况 | $ O(n^2) $      |
>
> 尽管最坏情况为 $ O(n^2) $，快速排序在大多数情况下仍然表现较好，平均时间复杂度为 $ O(n \log n) $，且由于其低常数项和原地排序的特性，通常比归并排序快。



**性质**：

- 适合长距离交换，不稳定。
- 纯快速排序不适合小数组。
- “就地”，但由于递归调用而使用辅助存储（$O(logN)$ 空间）。
- 快速排序平均使用很少的比较。
- 快速排序在内存层次结构中确实有很好的性能。
  - 占地面积小，地段好。



## 桶排序

桶排序按下列步骤进行：

1. 设置一个定量的数组当作空桶；
2. 遍历序列，并将元素一个个放到对应的桶中；
3. 对每个不是空的桶进行排序；
4. 从不是空的桶里把元素再放回原来的序列中。



补充一些概念：

- **键值**：用于确定最终排序数组中记录的位置，可以理解为在哪一个桶。
- 仅适用于从 $0$ 到 $N-1$ 的数字排列。$N$范围不能太大。
- 时间花费是$\Theta(n)$，不管键值的最初排序是如何。



```cpp
/**
* Bucket Sort
* Allow for duplicate values among keys
* Allow for a set of N records falling in a range larger
* than N ([0,MaxKeyValue-1])
**/
template <typename E, class getKey>
void bucketsort(E A[], int n) {
    List<E> B[MaxKeyValue]; //An array of linked lists
    E item;
    //assign records to bins
    for (i=0; i<n; i++)
        //All records with key value i are placed in bin B[i]
        B[getKey::key(A[i])].append(getKey::key(A[i]));
    
    //process MaxKeyValue bins to output records
    for (i=0; i<MaxKeyValue; i++)
        for (B[i].setStart(); B[i].getValue(item); B[i].next())
        	output(item);
}
```

**进一步概括桶排序的思想**：

- 每个桶都与一系列键值相关联，而不是单个键值。
- 桶排序将记录分配给桶，然后依靠其他排序技术对每个桶内的记录进行排序。
- 通过相对便宜的分桶过程将少量记录放入每个桶中，桶内的清理排序相对便宜。



时间复杂度分析：

- $O(n)$用于将 `N`条记录分配给存储桶。

- 所有内部排序的总时间成本：取决于内部排序的实现方法。

- 扫描键值`MaxKeyValue`输出`N`条记录：

  - 如果`MaxKeyValue`是$\Theta(N)$的，那么时间复杂度是$\Theta(N)$。
  - 如果`MaxKeyValue`是$\Theta(N^2)$的，那么时间复杂度是$\Theta(N^2+N)$。
  - 当键值范围过大时，需要的空间也会变大，推荐在键值范围较小时使用。
  
  > 桶排序的时间复杂度主要依赖于**元素的分布情况**以及**桶内排序的效率**。下面将分别分析桶排序的最佳、最坏和平均时间复杂度。
  >
  > ### 1. 最佳情况：$O(n)$
  >
  > 当数据**均匀分布**在各个桶中时，桶排序的效率最高。假设有 $ n $ 个元素，将其分配到 $ k $ 个桶中，且每个桶中平均有 $ n/k $ 个元素。
  >
  > 在这种情况下：
  >
  > 1. **分配到桶**的时间复杂度为 $O(n)$，因为每个元素根据其值确定桶的位置，并放入对应的桶。
  > 2. **桶内排序**：由于每个桶内平均有 $ n/k $ 个元素，且在理想情况下，桶内排序时间复杂度为 $ O((n/k) \log(n/k)) $。总共有 $ k $ 个桶，因此所有桶内排序的总时间为：
  >    $$
  >    k \cdot O\left(\frac{n}{k} \log \frac{n}{k}\right) = O(n \log \frac{n}{k})
  >    $$
  >    若 $ k \approx n $ （每个桶内平均只有常数个元素），则桶内排序的时间复杂度可以简化为 $ O(n) $。
  >
  > 因此，在均匀分布的最佳情况下，桶排序的总时间复杂度可以达到 $ O(n) $。
  >
  > ### 2. 最坏情况：$O(n^2)$
  >
  > 在最坏情况下，所有元素集中到一个桶内，导致桶内排序的时间复杂度降为 $ O(n \log n) $ 或更差。如果桶内使用的是插入排序，则最坏情况下排序复杂度为 $ O(n^2) $。因此，当数据分布极端不均匀时，桶排序会退化为 $ O(n^2) $ 的复杂度。
  >
  > ### 3. 平均情况：$O(n + n \log \frac{n}{k})$
  >
  > 在平均情况下，假设数据**大致均匀分布**，且桶的数量 $ k $ 与 $ n $ 是同数量级（例如 $ k \approx n $）。则桶内元素数量较少，使得桶内排序开销较小。
  >
  > 平均情况下，桶排序的时间复杂度为：
  >
  > $$
  > O(n) + O\left(n \log \frac{n}{k}\right)
  > $$
  > 其中 $ O(n) $ 是分配到桶的开销，$ O\left(n \log \frac{n}{k}\right) $ 是桶内排序的总开销。若 $ k $ 接近 $ n $，则这个表达式可以简化为 $ O(n) $。
  >
  > 因此，在平均情况下，桶排序的时间复杂度接近 $ O(n) $。
  >
  > ### 总结
  >
  > | 情况     | 时间复杂度                                |
  > | -------- | ----------------------------------------- |
  > | 最佳情况 | $ O(n) $                                  |
  > | 平均情况 | $ O(n) $ 或 $ O(n + n \log \frac{n}{k}) $ |
  > | 最坏情况 | $ O(n^2) $                                |
  >
  > 桶排序的时间复杂度表现非常依赖数据的分布情况。在实际应用中，如果数据的范围和分布适合分桶，桶排序能提供接近线性时间复杂度的高效排序。



## 基数排序

将记录分配给桶，桶是根据**基数或键值的基数**计算的。

- 适合用于任何数量的桶
- 可以扩展到任意键范围内任意数量的键
- 可以扩展到任意键范围内任意数量的键
- 下面是一个非常好的例子解释：

![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202411231835833.webp)

通俗一点的讲，我们将要比较的元素统计转换为同一进制下的元素，将每个元素当作字符串，从**低到高位**进行逐位比较。

> 基数排序（Radix Sort）是一种非比较排序算法，通常用于整数或字符串的排序。它按照数位（个位、十位、百位等）或字符位置对数据进行多次排序。基数排序有两种主要实现方式：**LSD（Least Significant Digit，最低位优先）**和**MSD（Most Significant Digit，最高位优先）**，其中 LSD 基数排序较为常用。
>
> ### 1. 基数排序的过程
>
> 假设有 $ n $ 个整数，每个整数包含 $ d $ 位（如最大值在 1000 以内，则 $ d = 3 $）。基数排序的步骤如下：
>
> 1. 从最低位（个位）开始，对所有元素按这一位的数值进行稳定排序（如计数排序或桶排序）。
> 2. 依次对更高位（十位、百位等）进行排序，直到最高位为止。
> 3. 最终得到有序数组。
>
> ### 2. 时间复杂度分析
>
> 基数排序的时间复杂度依赖于**每次数位排序的时间复杂度**以及**数位的数量**。
>
> #### LSD 基数排序的复杂度
>
> 1. **每次数位排序**：基数排序通常使用**计数排序**或**桶排序**来对每个数位进行排序，这样可以在 $ O(n) $ 的时间内完成数位排序（因为计数排序的时间复杂度是 $ O(n + k) $，而基数的 $ k $ 通常是固定的常数，如 10）。
> 2. **数位数量**：假设最大数是 $ d $ 位数，基数排序需要进行 $ d $ 次数位排序。
>
> 因此，LSD 基数排序的时间复杂度为：
>
> $$
> O(d \cdot (n + k))
> $$
> **补充一下计数排序**：
>
> 计数排序的工作原理是使用一个额外的数组 $C$，其中第个元素是待排序数组  中值等于  的元素的个数，然后根据数组 来将 中的元素排到正确的位置。
>
> 1. 计算每个数出现了几次；
> 2. 求出每个数出现次数的前缀和；
> 3. 利用出现次数的前缀和，从右至左计算每个数的排名。
>
> ```cpp
> constexpr int N = 100010;
> constexpr int W = 100010;
> 
> int n, w, a[N], cnt[W], b[N];
> 
> void counting_sort() {
>   memset(cnt, 0, sizeof(cnt));
>   for (int i = 1; i <= n; ++i) ++cnt[a[i]];
>   for (int i = 1; i <= w; ++i) cnt[i] += cnt[i - 1];
>   for (int i = n; i >= 1; --i) b[cnt[a[i]]--] = a[i];
> }
> ```
>
> 在实际应用中，基数 $ k $ 是一个常数（如 10 表示十进制），因此时间复杂度可以简化为：
> $$
> O(d \cdot n)
> $$
> 
>
> #### 对 $ d $ 的分析
>
> - **当 $ d $ 为常数**（即数据位数固定，如 32 位整数）：时间复杂度为 $ O(n) $。
> - **当 $ d $ 与 $ n $ 有对数关系**（即最大元素大约为 $ n^c $ 量级）：此时 $ d = O(\log n) $，所以时间复杂度为 $ O(n \log n) $。
>
> ### 3. 空间复杂度
>
> 基数排序的空间复杂度主要取决于计数排序的辅助数组。由于每次排序使用额外的 $ O(n + k) $ 空间，因此空间复杂度为：
>
> $$
> O(n + k)
> $$
>
> ### 4. 基数排序的适用场景
>
> 基数排序适合用于：
>
> - 数值范围较大的非负整数排序。
> - 数据位数不多，或数位数量较小时的整数或字符串排序。
> - 要求稳定排序的场景（基数排序是稳定的）。
>
> ### 5. 总结
>
> | 情况         | 时间复杂度       | 空间复杂度   |
> | ------------ | ---------------- | ------------ |
> | **基数排序** | $ O(d \cdot n) $ | $ O(n + k) $ |
>
> 基数排序能在数据位数有限的情况下提供接近线性的时间复杂度，适合用于特定场景的大规模数据排序。



实现代码：

```cpp
/*
* Radix sort an array of Strings.
* Assume all characters are ASCII, residing in the first 256
* positions of the Unicode character set.
* Assume all have same length(stringLen).
*/
void radixSortA( vector<string> & arr, int stringLen ){
    const int BUCKETS = 256;
    vector<vector<string>> buckets( BUCKETS );
    for( int pos = stringLen - 1; pos >= 0; --pos ){
        for( string & s : arr )
            //Adds s at the end of the buckets[ s[ pos ] ]
            buckets[ s[ pos ] ].push_back( std::move( s ) );
        int idx = 0;
        for( auto & thisBucket : buckets ){
            for( string & s : thisBucket )
            	arr[ idx++ ] = std::move( s );
            thisBucket.clear( );
        }
    }
}
```



**另外一种实现（推荐）：时间复杂度为$O(d\cdot(n+k))$。**

$d=log_bn$，对应的渐近时间复杂度为$\Omega(NlogN)$。

```cpp
/*
* Counting radix sort
* B[] is array for buckets
* cnt[i] stores numbers of records in bucket[i]
* b is numbers of buckets(base), r is number of passes
*/
template <typename E, typename getKey>
void radix(E A[], E B[], int n, int r, int b, int cnt[]) {
    int j;
    for (int i=0, btoi=1; i<r; i++, btoi*=b) {//for r digits
        for (j=0; j<b; j++) cnt[j] = 0;
        //Count # of records for each buckets on this pass
        for(j=0; j<n; j++) cnt[(getKey::key(A[j])/btoi)%b]++;
        
        //Index B: cnt[j] will be index for last slot of bucket j.
        for (j=1; j<b; j++) cnt[j] += cnt[j-1] ;
        
        /*Put records into buckets, from bottom of each bucket.*/
        for (j=n-1; j>=0; j--)
        B[--cnt[(getKey::key(A[j])/btoi)%b]] = A[j];
        
        for (j=0; j<n; j++) A[j] = B[j]; //Copy B back to A.
    }
}
```



## 下界分析

排序算法的边界是${\Omega(N)}$和$O(NlogN)$。

- 任何算法都无法在小于$\Omega(N)$的时间内解决排序问题。
- 当前最著名的排序算法是$ O(NlogN)$（对于平均情况和最坏情况）



这里引入决策树进行解释：

- **决策树是一棵二叉树，可以对任何做出二元决策的算法的处理进行建模。**
- **二元决策：是或否；小于或大于**
- **每个决策都由树中的一个分支表示**



具体地讲：**所有排序算法都可以被视为“找到”产生排序列表的输入的正确排列的算法**，根据比较结果在树中进行分支，一旦到达具有单个排列的叶子，算法完成。

最深节点的深度代表算法达到答案所需的最长决策系列，它对应于算法最坏情况的成本！

任何仅使用比较的排序算法至少需要 $log (N!)$（最坏情况下的比较）。最终得到的是$\Omega(NlogN)$。

> 是的，还有其他分析方法可以帮助我们理解 $\log 1 + \log 2 + \cdots + \log n = \Theta(n \log n)$ 的成立。一个常用的方法是用**积分逼近**来估计累加和的增长率。
>
> ### 方法二：积分逼近
>
> 考虑到 $\log 1 + \log 2 + \cdots + \log n$ 是一个关于 $\log k$ 的离散和，我们可以用积分来逼近其结果，因为积分可以作为累加的近似。
>
> 1. **设定积分逼近**：
>    
>    $$
>    \sum_{k=1}^n \log k \approx \int_1^n \log x \, dx
>    $$
>    
>    
> 2. **计算积分**：
>
>    我们计算积分 $\int \log x \, dx$。使用分部积分法，有：
>
>    $$
>    \int \log x \, dx = x \log x - x + C
>    $$
>    
>
>    因此，
>
> $$
>    \int_1^n \log x \, dx = \left[ x \log x - x \right]_1^n
> $$
>    
>
>    代入上、下限 $x = n$ 和 $x = 1$，得到：
>
> $$
>    \int_1^n \log x \, dx = \left( n \log n - n \right) - (1 \cdot \log 1 - 1) = n \log n - n + 1
> $$
>    其中，$1$ 是一个常数项，可以在渐进分析中忽略。
>
> 3. **简化结果**：
>
>    我们得到：
>
>    $$
>    \sum_{k=1}^n \log k \approx n \log n - n + 1
>    $$
>    对于大 $n$ 的情况，$n \log n$ 是主导项，而 $-n$ 和常数项 $+1$ 是低阶项，因此我们可以忽略它们，只保留主导项：
>    
>    $$
>    \sum_{k=1}^n \log k = \Theta(n \log n)
>    $$
>
> ### 总结
>
> 通过积分逼近的方法，我们再次得到了同样的结论：$\log 1 + \log 2 + \cdots + \log n$ 的渐进增长率是 $\Theta(n \log n)$。



我们也可以将决策树用于以下问题：

- 找到$N$个元素中的最小元素。
- 找到$N$个元素中的两个最小元素。
- 找到中位数。

一般化：找第$k$小的数，我们可以采用决策树分析下界，下面针对这个问题进行分析：

我们需要进行$N - k + \lceil \log \binom{N}{k-1} \rceil$次比较。

> 在这个幻灯片中，它讨论了选择问题（selection problem）的决策树下界（lower bounds），用于说明在找到第 $ k $ 小的元素时所需的最少比较次数。我们可以分解内容来解释为什么需要这些比较。
>
> ### 1. 假设所有元素都是唯一的
> 假设所有元素都是唯一的，意味着我们不需要考虑重复元素的情况，这样可以简化问题。
>
> ### 2. 为什么需要 $N - k + \lceil \log \binom{N}{k-1} \rceil$ 次比较？
> 找到第 $ k $ 小的元素，实际上是要确定前 $ k $ 小的元素的集合以及它们之间的相对顺序。在决策树模型中，通过每一次比较，可以排除某些不可能成为第 $ k $ 小的元素的候选项，从而缩小搜索空间。
>
> 对于选择问题的下界，要求找到第 $ k $ 小的元素需要：
> - **$N - k$ 次比较**来排除掉 $ N - k $ 个较大的元素。
> - **$\lceil \log \binom{N}{k-1} \rceil$ 次比较**来在剩余的 $ k $ 个元素中找到第 $ k $ 小的。这里，$\log \binom{N}{k-1}$ 表示我们在 $ k-1 $ 个元素的组合中选择第 $ k $ 小元素所需的比较次数的下界。换句话说，$\binom{N}{k-1}$ 表示从 $ N $ 个元素中挑选出 $ k-1 $ 个元素的方法数，而找到第 $ k $ 小的元素相当于从这些方法中确定唯一解。
>
> ### 3. 为什么找到最小的元素需要 $N-1$ 次比较？
> 对于找到最小的元素的情况，这是一个特殊情况，即 $k = 1$。在这种情况下，我们只需要从所有 $ N $ 个元素中找到一个最小的，且每个元素都需要与其他元素比较以确定是否是最小的。因此，找到最小元素至少需要 $ N - 1 $ 次比较。
>
> ### 总结
> 这个下界结果说明，任何基于比较的算法，在寻找第 $ k $ 小的元素时，必须至少进行 $N - k + \lceil \log \binom{N}{k-1} \rceil$ 次比较。这给出了选择问题的一个理论下界，表明无论采用什么算法，这些比较次数都是不可避免的。



## 外部排序

外部排序算法旨在处理非常大的输入（输入太大，无法装入内存）。

**具体介绍外部排序的处理思想**：

- 从磁盘中读取一些记录
- 进行一些重新排序
- 将他们写回到大容量存储设备中
- 重复该过程，直到文件排序完毕

**主要目标**：最大限度地减少从大容量存储设备读取或写入信息的次数。



例子：记录存储在磁盘上，只能按照顺序访问。

**假设算法将会在至少三个磁带上访问**。

外部归并排序：假设在四个磁带上：$Ta1,Ta2,Tb1,Tb2$，数据最初位于$Ta1$上，且内存一次可以存储$M$条记录，这里$M=3$。

![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202411101020715.webp)

这里解释一下：先将81 94  11存入$Tb1$中，再将96 12 35存入$Tb2$中，再将17 99 28存入$Tb1$中，依次类推。

![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202411101019198.webp)

然后使用归并排序：将$Tb1,Tb2$中的两个第一个三元块进行合并，存放到$Ta1$中，再将$Tb1,Tb2$中的第二个三元块进行合并，存放到$Ta2$中，以此类推。

后面的处理也是采取类似的方法。

![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202411101019117.webp)

**分析时间复杂度**：需要进行$\lceil log\frac{N}{M}\rceil$遍，此外还有依次初始构造。

**e.g**：1000万（$10\times 2^{20}$）记录，每条$128(2^7)$字节，内存中每次可以最多存储$4\times2^{20}$字节，计算可以得到运行时间为$log\frac{10\times2^{20}\times 2^7}{4\times 2^{20}}=log320=9$，所以需要进行$9$次合并。



**改进算法**：

- 初始运行时构建尽可能大的块
- 增加每次传递期间合并在一起的运行次数，这里介绍**多路合并**。



多路合并是将双路合并扩展到$k$路，工作方法与上面的相同，**不同之处在于找到$k$个元素中最小的元素，使用优先队列解决这个问题**。

![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202411101050790.webp)

![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202411101050798.webp)

![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202411101050091.webp)

使用这种多路合并的方法时，计算方法如下：

e.g $320$次初始运行，$5$次合并，计算时间为$\lceil log_5320\rceil=4$次。



创建尽可能大的初始运行，假设可用内存为$M$条记录，这里引入**替换选择**算法来创建平均长度为$2M$的记录。

- 将$M$条记录读入到内存中，设置$LAST=M-1$；
- 将这$M$条记录放到一个最小堆中，
- 重复下述操作，直到堆为空，重新构建：
  - 执行`deleteMin`操作
  - 令$R$为输入中的新记录，如果$R>Min$，那么$R$插入堆中，否则将$R$存储再$LAST$位置的内存中，并且$LAST--$。
  - 堆为空，重新建堆。

> 替换选择算法（Replacement Selection Algorithm）是一种外部排序算法，用于生成长的初始排序运行（runs），从而减少归并排序的归并轮数。该算法在内存受限的情况下生成更长的有序数据序列，使得最终的外部归并排序更加高效。替换选择算法通常在磁盘文件的排序中使用，例如数据库中的大文件排序。
>
> ### **算法原理**
> 替换选择算法利用一个最小堆来构建有序的初始运行。算法会从输入数据流中读取数据，放入堆中，并保持堆的有序性。堆中元素不断更新和替换，以生成尽可能长的排序序列。具体步骤如下：
>
> 1. **初始化**：将内存中容纳的数据量（例如，$ M $ 个元素）放入一个最小堆。
> 2. **生成初始运行**：
>    - 从堆中取出最小元素，将其写入输出文件。
>    - 从输入流中读取下一个元素：
>      - 若新元素比刚写出的元素大，则将该新元素插入堆中，保持堆的有序性。
>      - 若新元素比刚写出的元素小，则将其视为下一轮的元素，将其放入一个备用区域（通常是一个新堆或标记为“冷区”）。
>    - 重复上述步骤，直到堆中的元素全部被移除。此时便完成一个初始运行。
> 3. **生成下一轮运行**：将备用区域中的元素重新加载到堆中，重复以上步骤，生成下一轮的初始运行。
>
> ### **优点**
> 替换选择算法可以在内存有限的情况下生成较长的初始有序序列，从而减少归并排序的轮数，降低了外部排序的总时间和I/O成本。
>
> ### **示例**
> 假设有一组数据流 `[7, 3, 9, 10, 4, 6, 8]`，且内存只能容纳三个元素。
>
> 1. **初始堆**：加载前三个元素 `[7, 3, 9]`，形成最小堆 `[3, 7, 9]`。
> 2. **开始生成初始运行**：
>    - 取出堆顶 `3`，写入输出。
>    - 读取新元素 `10`（大于3），将 `10` 插入堆，堆变为 `[7, 9, 10]`。
>    - 取出堆顶 `7`，写入输出。
>    - 读取新元素 `4`（小于7），将 `4` 存入备用区。
> 3. 重复此过程直至堆为空，生成的初始运行为 `[3, 7, 9, 10]`。备用区中的元素用于下一轮运行。
>
> ### **复杂度分析**
> 替换选择算法的时间复杂度为 $O(N \log M)$，其中 $N$ 为数据总量，$M$ 为内存大小（堆的容量）。

一个简单的示例如下：

![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202411101107782.webp)

最初构建只有三个元素81 94 11，然后删除11，将11写入到输出中，发现新元素是96，比11小，所以插入到堆中。

第二次操作：删去并将81写入到输出中，发现新元素12小于81，所以不插入到堆中，放到备用区。

第三次操作：删去并将94写入到输出中，发现新元素35小于94，所以不插入到堆中，放到备用区。

![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202411101107681.webp)

第四次操作：删去并将96写入到输出中，发现堆为空，重新建堆。

后续处理按照上述的思路进行。

![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202411101107760.webp)

![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202411101107193.webp)

