# Ch3a

- **理想内存特性**：
  - 容量大。
  - 速度快。
  - 非易失性。
  - 成本低。
- **内存层次**：
  - **高速缓存（Cache）**：容量小，速度快，易失性。
  - **主内存（RAM）**：容量中等，速度中等，易失性。
  - **磁盘存储**：容量大，速度慢，非易失性。
- **内存管理器**：管理内存层次，优化内存使用。

存储器的层次结构如下：

![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505261413498.webp)

必须**将 Program 放入内存并放置在进程中才能运行**。内存中的连续地址空间（memory unit），用于存储进程的代码和数据，一般划分为**系统部分和用户部分**。



**内存管理的目标**

1. **支持多程序运行**。
2. **方便用户使用**：隐藏硬件细节，自动加载用户程序。
3. **解决程序空间大于内存空间的问题**。
4. **提高内存利用率**。
5. **保护和安全性**：防止进程相互干扰。
6. **共享和通信**：允许多个进程共享内存。
7. **性能和成本**：优化内存访问速度和成本。

**内存管理的任务**

1. **内存分配和释放**。
2. **地址重定位**。
3. **内存共享和保护**。
4. **内存扩展**。



## 3.1 无内存抽象

- **定义**：最简单的内存管理方式，程序直接看到物理内存。

- **问题**：**无法同时运行多个程序，因为它们会相互干扰**。细分如下：

  - 保护：系统如何防止进程相互干扰？
  - 重分配（Relocation）：
    - 进程**不能放回同一主内存**区域
    - 任务或进程**如何在主内存中的不同位置**运行？


  该问题在后续中也非常关键，是多程序问题需要考虑的。

- 组织用户内存和系统内存的三种方案：

  ![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505261417047.webp)

- **解决方案**：通过硬件支持（如IBM 360的保护键）和静态重定位来实现多程序运行。具体如下：

  ![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505261422512.webp)

  发生了读取错误，找不到目标地址。

  **解决方案如下：加载过程时静态修改地址。**

  ![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505261424612.webp)

- 静态重定位：

  - **定义**：**在加载程序时静态修改地址。**

  - **优点**：**不需要硬件支持**。

  - **缺点**：
    - **加载速度慢**。
      - 一旦加载，程序的代码或数据**不能在内存中移动**。
      - 加载器需要区分地址和常量。

## 3.2 地址空间
- **定义**：地址空间是进程可以用来寻址内存的一组地址。
- **逻辑地址空间**：进程看到的地址范围（0到最大值）。**独立于其他进程的地址空间，只有自己可见**。
- **物理地址空间**：实际的内存地址范围。
- **地址绑定**：将**程序指令和数据**的地址与**物理内存地址**关联的过程。即逻辑地址空间到物理地址空间。



**Base and Limit Register**

![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505261433867.webp)

**基址寄存器 (Base Register)**

- **作用**：存储进程在物理内存中的**起始地址**（即逻辑地址0对应的物理地址位置）。
- **工作原理**：
  CPU生成的**逻辑地址会被自动加上基址寄存器的值，转换为物理地址**。
  **公式**：`物理地址 = 逻辑地址 + 基址寄存器值`
  （例如：基址=16384，逻辑地址28 → 物理地址16412）

**界限寄存器 (Limit Register)**

- **作用**：定义进程地址空间的**最大允许范围**（通常以字节为单位），防止进程越界访问其他进程或操作系统内存。
- **工作原理**：
  每次内存访问前，CPU会**检查逻辑地址是否小于界限寄存器的值。若越界，触发硬件异常（如段错误）。**
  **验证条件**：`逻辑地址 < 界限寄存器值`

两者用于确定每个进程单独的地址空间。使用的是动态重定位，具体参考如下。



**动态重定位**

- **定义**：在运行时**将进程的地址空间映射到物理内存的不同部分**。
- **硬件支持**：需要基址寄存器和限长寄存器。
- **优点**：
  - 操作系统可以**动态移动进程**。
  - **进程可以随着时间增长**：OS 更改limit寄存器或者移动。
  - **简单，快速：需要两个寄存器：Add 和 compare**
- **缺点**：
  - 每次内存访问**都需要额外的加法操作**。
  - **不能共享内存**。
  - **进程受限于物理内存大小**。
  - **复杂化内存管理**。



**交换（Swapping）**

原因是：程序数量众多，总大小超过了内存空间。

交换允许多个进程共享一个分区。（？）

- **定义**：将整个进程**从磁盘调入内存运行一段时间，然后换出**。

- **虚拟内存**：允许程序**在仅部分加载到内存的情况下运行**。

- **内存分配**：动态分配内存，根据进程需求分配空间。

  ![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505261443796.webp)

- 针对会**增长的进程，可以更大的分区中换出或者换回，问题是成本高**

  ![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505261446217.webp)

- **问题**：外部碎片化，内存中出现许多小的空闲块。这时候就**需要引入紧凑化方法，解决外部碎片的问题**。

  **外部碎片化**：

  ![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505261447743.webp)

  ![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505261447198.webp)

  ![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505261447577.webp)



**紧凑化（Compaction）**

- **定义**：将内存中的空闲块合并成一个大的空闲区域。
- **优点**：**减少外部碎片化**。
- **缺点**：**需要暂停进程，增加系统开销**。
- **要求**：所有程序都是可以重新定位的。

![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505261449676.webp)



**内存管理方法**

通过使用位图或者链表跟踪内存的使用情况。

- **位图（Bitmap）**：

  - **每个分配单元对应位图中的一个位。0 表示空闲，1 表示已分配。**
  - 优点：**简单直观**。
  - 缺点：查找空闲块速度慢。**如果要为一个新到达的进程分配存储空间时，需要找到连续的 0 位。**
  - 分配单元越小，位图越大（很好理解）。

- **链接列表（Linked Lists）**：

  - 链表中的每个条目指定**一个空闲块**或已分配块的**起始地址和长度**。此外还有指向下一个条目的指针。
  - 一般**按照地址或者大小进行排序**。
  - 优点：动态管理内存。
  - 缺点：更新操作复杂。

  ![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505261457108.webp)

  - 推荐**按照地址排序，容易增删查改内存空间，非常简单**。

    ![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505261459717.webp)

    

**存储放置策略**

- **首次适应（First Fit）**：使用第一个足够大的空闲块，即首个满足地址空间需求的的空闲块
- **下次适应（Next Fit）**：从上次停止的地方开始查找。性能略差于 First Fit。
- **最佳适应（Best Fit）**：使用最接近需求的空闲块。
- **最坏适应（Worst Fit）**：使用最大的空闲块。
- **快速适应（Quick Fit）**：为常见大小维护单独的列表。

> ### **1. First Fit（首次适应）**
> - **原理**：从内存起始位置开始搜索，选择 **第一个足够大** 的空闲分区。
> - **示例**：  
>   空闲分区列表：`[10KB, 30KB, 20KB]`  
>   请求 `15KB` → 分配 `30KB`（第一个满足的分区）
> - **特点**：
>   - **优点**：**简单快速，保留大分区供后续需求。**
>   - **缺点**：可能产生较多外部碎片（**小碎片集中在低地址**）。
> - **适用场景**：通用场景，平衡速度和碎片。
>
> ---
>
> ### **2. Next Fit（下次适应）**
> - **原理**：类似首次适应，但从 **上次分配结束的位置** 开始搜索（循环遍历）。
> - **示例**：  
>   上次分配在 `30KB` 分区，空闲列表：`[10KB, 30KB, 20KB]`  
>   请求 `15KB` → 从 `30KB` 后开始搜索，分配 `20KB`。
> - **特点**：
>   - **优点**：**比首次适应更均匀地分布碎片。**
>   - **缺点**：可能**跳过较大的空闲分区**，导致大请求无法满足。
> - **适用场景**：需要**减少低地址碎片**的情况。
>
> ---
>
> ### **3. Best Fit（最佳适应）**
> - **原理**：搜索 **最小但足够大** 的空闲分区（满足需求的最小分区）。
> - **示例**：  
>   空闲分区列表：`[10KB, 30KB, 20KB]`  
>   请求 `15KB` → 分配 `20KB`（最接近需求的分区）。
> - **特点**：
>   - **优点**：减少大分区被拆分的次数。
>   - **缺点**：**产生大量微小碎片（需频繁合并），搜索速度慢**（需遍历所有分区）。
> - **适用场景**：内存利用率优先的场景。
>
> ---
>
> ### **4. Worst Fit（最差适应）**
> - **原理**：搜索 **最大的空闲分区** 进行分配。
> - **示例**：  
>   空闲分区列表：`[10KB, 30KB, 20KB]`  
>   请求 `15KB` → 分配 `30KB`（最大分区）。
> - **特点**：
>   - **优点**：**减少微小碎片，适合大请求**。
>   - **缺点**：可能耗尽大分区，导致**后续大请求**无法满足。
> - **适用场景**：预期**后续多为小请求**的场景。
>
> ---
>
> ### **5. Quick Fit（快速适应）**
> - **原理**：维护 **多个独立链表**，按**常见分区大小分类**（如4KB、8KB等）。
> - **示例**：  
>   预设链表：`4KB链表`、`8KB链表`、`16KB链表`  
>   请求 `5KB` → 直接从 `8KB` 链表分配。
> - **特点**：
>   - **优点**：**分配极快**（O(1)时间复杂度）。
>   - **缺点**：合并碎片复杂，**需额外维护多个链表**。
> - **适用场景**：频繁分配固定大小内存（如操作系统内核）。
>
> ---
>
> ### **策略对比总结**
> | 策略          | 搜索方式           | 速度 | 碎片问题     | 适用场景         |
> | ------------- | ------------------ | ---- | ------------ | ---------------- |
> | **First Fit** | 从头搜索第一个满足 | 快   | 中等外部碎片 | 通用             |
> | **Next Fit**  | 从上次位置搜索     | 较快 | 碎片分布均匀 | 避免低地址碎片   |
> | **Best Fit**  | 搜索最小满足分区   | 慢   | 大量微小碎片 | 内存利用率优先   |
> | **Worst Fit** | 搜索最大分区       | 慢   | 保留大分区   | 预期后续多小请求 |
> | **Quick Fit** | 直接匹配预设链表   | 极快 | 合并困难     | 固定大小分配     |
>
> ---
>
> ### **选择建议**
> - **追求速度**：`Quick Fit` > `First Fit` > `Next Fit`  
> - **减少碎片**：`Best Fit`（小碎片）或 `Worst Fit`（保留大分区）  
> - **平衡型**：`First Fit` 是大多数系统的默认选择。



---



> 在内存管理的放置策略中，**First Fit（首次适应）通常优于 Next Fit（下次适应）**，主要原因如下：
>
> ---
>
> ### **1. 搜索效率更高**
> - **First Fit**：  
>   从内存的 **起始位置** 开始搜索，找到第一个满足条件的空闲分区即停止。  
>   - **优势**：在内存前半部分存在较多空闲块时，能快速命中。
> - **Next Fit**：  
>   从 **上次分配结束的位置** 开始搜索（循环遍历）。  
>   - **问题**：若上次分配点在内存中部，可能跳过前面较大的空闲分区，导致需要遍历更多次才能找到合适块。
>
> **示例**：  
> 空闲分区列表：`[10KB, 30KB, 20KB]`  
> - First Fit 请求 `15KB` → 直接分配 `30KB`（首次命中）。  
> - Next Fit 若上次停在 `30KB`，下次请求 `15KB` 需跳过 `10KB`，分配 `20KB`（效率更低）。
>
> ---
>
> ### **2. 碎片化更可控**
> - **First Fit**：  
>   优先使用低地址的空闲分区，可能导致 **低地址外部碎片**，但**大分区保留在高地址，适合后续的大请求**。  
> - **Next Fit**：  
>   分配位置分散，碎片分布更随机，可能 **提前分割大分区**，**导致后续大请求无法满足**。
>
> **示例**：  
> 多次分配后：  
> - First Fit 可能保留高地址的 `50KB` 大分区。  
> - Next Fit 可能将大分区拆分为多个小块，导致无法分配 `40KB` 的请求。
>
> ---
>
> ### **3. 实现简单**
> - **First Fit**：  
>   **只需维护一个单向链表，从头开始线性搜索**。  
> - **Next Fit**：  
>   需记录上次分配位置，**增加状态管理复杂度**（尤其在多线程环境下）。
>
> ---
>
> ### **4. 局部性更优**
> - **First Fit**：  
>   集中使用低地址空间，可能提升 **缓存命中率**（CPU缓存更易预取连续地址）。  
> - **Next Fit**：  
>   分配跳跃性强，可能降低缓存效率。
>
> ---
>
> ### **何时 Next Fit 更优？**
> 在极端场景下，Next Fit 可能表现更好：  
> 1. **内存分配极度频繁**，且请求大小随机时，Next Fit 能避免低地址过度碎片化。  
> 2. **内存布局接近环形**（如嵌入式系统），Next Fit 的循环搜索更匹配硬件特性。
>
> ---
>
> ### **总结**
> | **维度**     | **First Fit**              | **Next Fit**                 |
> | ------------ | -------------------------- | ---------------------------- |
> | **速度**     | 更快（优先命中低地址大块） | 较慢（可能跳过合适块）       |
> | **碎片控制** | 保留高地址大分区           | 碎片分布随机，可能浪费大分区 |
> | **实现难度** | 简单                       | 需维护上次分配位置           |
> | **适用场景** | 通用场景（默认选择）       | 特殊场景（如环形内存布局）   |
>
> **结论**：在大多数情况下，First Fit 因简单、高效、碎片可控而优于 Next Fit。



![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505261510476.webp)





## 3.3 虚拟内存

**覆盖（Overlaying）**

- **定义**：将程序划分为多个小块，仅将部分块加载到内存中。
- **优点**：节省内存。
- **缺点**：**需要程序员手动划分程序，增加编程复杂性。**



**虚拟内存**

- **定义**：虚拟内存**将用户逻辑内存与物理内存分离，提供比物理内存更大的逻辑地址空间**。
- **实现**：==通过将虚拟内存存储在磁盘上，仅将部分程序加载到内存中运行==。
- **优势**：
  - **支持多程序运行。**
  - **提高内存利用率。**
  - **允许进程共享地址空间。**
  - **提高进程创建效率。**



**局部性原则**

在执行阶段，进程引用的页面的比例相对较小，即在时间或者空间上具有临近性，不会过于分散。



**实现方法一般有三种**

- **分页（Paging）**：
  - 将虚拟地址划分为固定大小的页面。
  - 将物理内存划分为页帧。
  - **使用内存管理单元（MMU）将虚拟地址转换为物理地址**。
  - 现代方法，目前最常见
- **分段（Segmentation）**：
  - **定义**：将程序逻辑上划分为多个段，每个段有自己的地址空间。
  - **优点**：
    - 更符合程序的逻辑结构。
    - **方便内存管理**。
  - **缺点**：
    - 需要**额外的硬件支持**。
    - **可能导致内部碎片**。

- **分页与分段结合**：结合两者的优点，提供更灵活的内存管理。



## 3.4 页面置换算法

**虚拟地址是进程用于访问其自身地址空间的内存地址，与存储进程的物理 RAM 地址不同**，MMU（内存管理单元）将虚拟地址空间转换为物理地址空间。OS 确定从虚拟地址到物理地址的映射。

虚拟地址空间被划分为多个单元，大小一般为 $2^n$ 字节。**这些单元一般称为page，其在物理内存中对应的单元称为 page  frame。**



![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505261529107.webp)



一般调用过程如下：

假设计算机可以生成 16 位地址 （0-64k）。但是，计算机只有 32k 的内存 ➔ 64k 的程序可以写入，但不能加载到内存中。**使用 Present/Absent 位跟踪页面是否已映射。一旦引用未映射的页面，CPU 会陷入到 OS 中。我们称该错误为 page fault（页面命中失败）**，此时，MMU 会选择一个较少使用的 page frame 进行替换，然后再次获取刚刚引用（需要的）page，重新继续执行指令。

- **页面置换**：**当内存中没有足够的空间时，选择一个页面将其置换到磁盘上。**
- **算法**：
  - **先进先出（FIFO）**：置换最早进入内存的页面。
  - **最近最少使用（LRU）**：置换最近最少使用的页面。
  - **最佳置换（OPT）**：置换**未来最长时间内不会被使用的页面**（理想算法）。



一般通过页表给出虚拟地址和物理地址之间的关系：

![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505261539071.webp)

![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505261540571.webp)



虚拟地址（由 CPU 生成）分为**页码（高位）和页偏移量（低位）**，对于给定的逻辑地址空间 $2^m$ 和页面大小 $2^n$

**其中 $m-n$ 位用于高位，即页码，其余 $n$ 用于页面偏移量。页码就是在页表中的索引。**



物理地址分为**帧号（frame number）和页面偏移量**，用途是将**虚拟页映射到页帧**上。

![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505261545383.webp)



![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505261546882.webp)



页表是由 OS 管理，**将 VPN（虚拟页码）映射到 PFN，两者一一对应。大多数 OS 位每个进程分配一个页表**。



典型的页表条目结构

- page frame number：映射page frame number
- **存在位**：1表示有效，0表示无效，不存在。
- **Protection**：保护位，允许的访问类型
- **修改位（脏位）**：在修改并写入磁盘时设置。
- **引用位：在引用页面时设置（帮助决定要驱逐哪个页面**）。
- **Caching disabled**：缓存用于将逻辑上属于磁盘的数据**保存在内存中，以提高性能**。



页表问题

- **由registers 数组组成的单页表**。当进程启动时，寄存器将加载页表。
  - **优势：简单**
  - 缺点：如果表很大，则成本高昂，并且在**每次上下文切换时加载整个页表会损害性能**。
- 一般实际上**将页表保留在内存中，单个寄存器指向表**
  - 优势：**上下文切换便宜**
  - 缺点：读取表条目时，**需要一次或多次内存引用**



此外，从虚拟地址到物理地址的过程中，程序只知道虚拟地址，可能需要跨越多个分层页表。因此，每个程序内存访问**都需要几个实际的内存访问**。**通过 TLB 缓存页表中的活跃部分**。



**TLB**

- **定义**：一种高速缓存，**用于存储最近使用的页面表条目**。
- **优点**：
  - **快速查找虚拟地址到物理地址的映射**。
  - 提高内存访问速度。
- **缺点**：
  - TLB未命中时**需要访问页面表，增加延迟**。
  - 需要**管理TLB的替换策略**。



**TLB 中的位**

- 公共（必要）位：
  - 虚拟页码：与虚拟地址匹配
  - 物理页码：与物理地址匹配
  - **有效位**
  - **访问位：内核、用户（nil、read、write）**
- 可选位：
  - **进程标签位**
  - **引用**
  - **修改**
  - **可缓存**

![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505261612141.webp)

1. 如果向 MMU 提供虚拟地址，则硬件会**通过同时（并行）比较所有条目来检查 TLB**。
2. 如果 match 成功，则**从 TLB 中获取页表条目，而不经过页表**。
3. 如果失败：
   1. MMU 检测 miss **并进行普通的页表查找**。
   2. 然后，**它将一个页表条目从 TLB 中驱逐出去，并用新条目替换它，以便下次在 TLB 中找到该页表条目**。



TLB 命中率：页面地址缓存命中率，即：在 Associative Memory 中**找到的时间页表条目的百分比**



硬件控制的 TLB：

- 在 TLB 未命中时：

  - 硬件将 PTE（页表条目）**加载到 TLB 中，如果没有空闲条目，则需要回写**。

  - **如果包含 PTE 的页面无效（即包含对应的物理地址的页码无效？），则生成错误**

  - VM 软件**执行故障处理**

  - 重新启动 CPU

- 在 TLB 命中时，硬件会检查有效位：

  - 如果**有效**，则**指向内存中对应的页帧**。
  - 如果无效，则硬件会**生成页面错误，执行页面错误处理，否则重新启动指令**。



软件控制的 TLB：

- 如果 TLB 未命中，则生成 TLB 故障，然后陷入到 OS 中。
  - 检查**包含 PTE 的页面是否在内存中，如果不是，则执行页面错误处理**
  - 如果**没有空闲条目，则写回，然后将 目标PTE 加载到 TLB 中**
  - 重新启动指令
- 在 TLB 中命中时，硬件会检查有效位：
  - 如果有效，则指向内存中对应的页帧
  - 如果无效，则硬件会生成页面错误，执行页面错误处理，否则重新启动指令。





**页面表的实现**：

- **单级页面表**：简单但可能非常大。
- **多级页面表**：通过分层减少页面表的大小。
- **倒排页面表（Inverted Page Table）**：每个物理页面框架一个条目，减少页面表的大小。



页面表问题

- **性能问题**：每次内存访问**都需要查找页面表，可能需要多次内存访问**。
- **解决方案**：
  - **硬件支持**：使用**硬件寄存器存储页面表**。
  - **软件支持**：**将页面表留在内存中，减少上下文切换的开销**。
  - **TLB（Translation Lookaside Buffer）**：**缓存页面表的活动部分，减少查找时间**。



**多级页面表**

由于页表可能非常大，因此一种解决方案是对页表进行分页

- **定义**：将页面表划分为多个层次，减少页面表的大小。
- **实现**：
  - 将页面号分为多个部分，分别作为不同层次页面表的索引。
  - 例如，32位地址空间，4KB页面大小：
    - 20位页面号，12位页面偏移。
    - 两级页面表：10位索引到顶级页面表，10位索引到二级页面表。
- **优点**：
  - **减少页面表的大小。**
  - 不需要将整个页面

![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505261629721.webp)

![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505261630236.webp)



**倒置页表**

主要思想：每个物理页帧一个 PTE，**物理页码用作表格的索引**。

- `Hash(Vpage, pid)`  to  Ppage
- 优点：**适用于大地址空间的小页表**
- 缺点：
  - **查找很困难**
  - **管理哈希链等开销**



**线性倒置页表**

- **每个物理页面框架一个条目**

- 条目由存储在该真实内存位置的页面的**虚拟地址以及拥有该页面的进程的相关信息**组成。（进程、虚拟页面）

- **物理页码用作表中的索引**

  ![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505261830942.webp)

  ![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505261830344.webp)



**哈希倒置页表**

在实际页表之前添加一个额外的级别，称为哈希表。

- 对**进程 ID 和虚拟页码**进行哈希处理，以获取哈希表中的条目
- 使用**哈希表进行哈希处理时，可能会出现冲突，可以使用链地址方法解决**。
- 在**倒排页表项中添加 next 字段以形成链表**（标题的索引在哈希表中）
- 优点：**具有良好的哈希方案和与物理内存大小成正比的哈希图**，$O(1)$ 时间复杂度。
- 缺点：管理哈希链等的开销。

![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505261833260.webp)

![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505261837201.webp)

**先通过 Hash 表，映射到了索引 0x0 上，然后通过链表**找到了目标。

![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505261839340.webp)

> 哈希页表（Hashed Page Table）相比传统线性页表（Linear Page Table）确实在某些场景下具有性能优势，但“更快”并非绝对，其优势主要体现在**空间效率和特定访问模式的优化**上。以下是具体分析：
>
> ---
>
> ### **1. 空间效率优势**
> - **传统线性页表**：  
>   需要为整个虚拟地址空间维护一个连续的数组，即使某些虚拟地址未被使用（如稀疏地址空间）。例如，64位系统若使用线性页表，页表大小会变得极其庞大（理论上可达 $2^{64-\text{page\_offset}}$ 项），实际不可行。
>   
> - **哈希页表**：  
>   通过哈希函数将虚拟页号（VPN）映射到固定大小的哈希表中，仅存储实际存在的页表项（PTE），**显著减少内存占用**。尤其适合**稀疏地址空间**（如大型但未完全使用的进程）。
>
> ---
>
> ### **2. 访问速度的权衡**
> - **传统页表**：  
>   若页表较小且能放入TLB（快表）或缓存中，通过数组索引（$O(1)$）访问速度极快。但在页表层级较深（如多级页表）时，需要多次内存访问。
>
> - **哈希页表**：  
>   - **优势**：在稀疏地址空间中，哈希表**避免了多级页表的层级遍历，可能减少内存访问次数**（尤其是结合TLB时）。  
>   - **劣势**：哈希冲突可能引入额外开销（如链式哈希需要遍历链表），哈希函数计算本身也有成本。若冲突频繁，性能可能劣于线性页表。
>
> ---
>
> ### **3. 适用场景**
> - **哈希页表更适合**：  
>   - **64位系统或稀疏地址空间**（如数据库、科学计算应用）。  
>   - 需要动态扩展的虚拟内存（哈希表可灵活扩容）。  
>   - 结合反向页表（Inverted Page Table）进一步节省空间。
>
> - **传统/多级页表更适合**：  
>   - 32位系统或地址空间密集的进程。  
>   - 硬件优化充分（如TLB命中率高）的场景。
>
> ---
>
> ### **4. 其他优化结合**
> 现代系统常**混合使用多级页表和哈希技术**：  
> - 例如，Linux在64位系统中使用**四级页表**，但对大地址空间会结合哈希优化。  
> - **TLB的存在**使得大部分访问无需触及页表，因此哈希页表的核心优势更体现在**减少内存占用**而非直接加速。
>
> ---
>
> ### **总结**
> 哈希页表的核心优势是**高效处理稀疏地址空间，节省内存**，而非单纯“更快”。其速度取决于具体实现（哈希函数质量、冲突处理方式）和硬件支持。在TLB未命中时，若哈希冲突少，可能比多级页表更快；反之则可能更慢。





> **哈希倒置页表（Hashed Inverted Page Table, HIPT）** 是一种用于**虚拟内存管理**的高效数据结构，主要用于解决传统页表（如多级页表）在**大地址空间**下内存占用过大的问题。它的核心思想是**通过哈希表减少页表项的数量**，从而节省内存开销。  
>
> ---
>
> ## **1. 传统页表的问题**
> 在传统页表（如多级页表）中：
> - 每个进程有一个独立的页表，存储所有虚拟页到物理页框的映射。
> - 如果虚拟地址空间很大（如64位系统），页表会占用过多内存（甚至比程序本身还大）。
>
> **例子**：  
> 64位系统，4KB页大小 → 虚拟地址空间有 $2^{52}$ 个页（因为 $2^{64} / 2^{12} = 2^{52}$）。  
> 如果每个页表项（PTE）占8字节，那么一个进程的页表大小可达 $2^{52} \times 8B = 32PB$（完全不可行！）。
>
> ---
>
> ## **2. 哈希倒置页表的原理**
> 哈希倒置页表的核心优化是：
> - **不再为每个虚拟页存储映射，而是只为已分配的物理页框存储反向映射**（即“倒置”）。
> - **使用哈希表加速查找**，避免线性扫描。
>
> ### **数据结构**
> 1. **全局唯一的哈希表**（所有进程共享）：
>    - 存储 `<虚拟地址, 进程ID>` → `物理页框` 的映射。
>    - 哈希表的键 = `(虚拟页号, 进程ID)`，值 = 物理页框号。
> 2. **冲突处理**：
>    - 哈希冲突时，使用**链式法**（链表）或**开放寻址法**存储多个条目。
>
> ### **地址转换过程**
> 1. **输入**：虚拟地址 `VA` 和当前进程的 `PID`。
> 2. **计算哈希**：  
>    $ \text{Hash}(\text{虚拟页号}, \text{PID}) $ 得到哈希桶索引。
> 3. **查找匹配项**：
>    - 遍历哈希桶，找到 `(虚拟页号, PID)` 匹配的条目。
> 4. **获取物理地址**：
>    - 若找到，返回对应的物理页框号。
>    - 若未找到（缺页），触发**缺页异常**，由操作系统处理。
>
> ---
>
> ## **3. 为什么叫“倒置”？**
> 传统页表：
> - 按虚拟页号索引，存储物理页框号（`VPN → PFN`）。
>
> 哈希倒置页表：
> - 按物理页框号索引（倒置），存储虚拟页号+进程ID（`PFN → (VPN, PID)`）。
> - 由于物理内存远小于虚拟内存，条目数量大幅减少。
>
> ---
>
> ## **4. 优缺点**
> ### **优点**
> ✅ **内存占用低**：  
>    - 只存储已分配的物理页框的映射，而不是所有虚拟页。  
>    - 适用于大地址空间（如64位系统）。  
>
> ✅ **全局共享**：  
>    - 所有进程共用一个哈希表，减少重复存储。  
>
> ### **缺点**
> ❌ **哈希冲突影响性能**：  
>    - 冲突较多时，查找时间可能变长（但通常比线性扫描快）。  
>
> ❌ **缺页处理较复杂**：  
>    - 需要遍历哈希链或重新哈希，可能比传统页表慢。  
>
> ❌ **TLB失效开销大**：  
>    - 如果TLB未命中，哈希查找比多级页表稍慢。  
>
> ---
>
> ## **5. 实际应用**
> - **IBM PowerPC** 和 **某些嵌入式系统** 使用哈希倒置页表。
> - **现代操作系统（如Linux）** 通常采用**多级页表+TLB**，但在某些场景（如虚拟化）可能结合哈希优化。
>
> ---
>
> ## **总结**
> 哈希倒置页表通过**哈希表+反向映射**，大幅减少页表内存占用，尤其适合64位大地址空间系统。虽然查找可能稍慢于多级页表，但在内存受限的场景下是一种高效的折中方案。



