# Ch3b

## 分页策略（Paging Policies）
分页策略主要涉及以下三个方面：
1. **页面获取策略（Fetch Strategies）**：决定何时将页面从外存（磁盘）加载到主存（内存）。
2. **页面置换策略（Replacement Strategies）**：决定当内存不足时，选择哪个页面从内存中移出。
3. **页面清理策略（Clean Strategies）**：决定何时将内存中的页面移出。

### 页面获取策略
1. **按需获取（Demand Fetching）**：
   - **原理**：只有当页面被访问时，才将其加载到内存中。
   - **步骤**：
     1. 发生页面故障（Page Fault）。
     2. **检查虚拟地址是否有效，若无效则终止进程。**
     3. 如果有效，**检查页面是否已在内存中（可能被其他进程使用）**，若在则跳到第7步。
     4. **查找空闲页面框（Page Frame）**。
     5. 将磁盘块映射到page frame，并**从磁盘加载到内存，挂起用户进程。**
     6. **磁盘读取完成后，更新虚拟内存映射**。
     7. 如有必要，重新启动进程。
   - **优点**：**节省内存，**避免加载不必要的页面**。**
   - **缺点**：可能导致频繁的页面故障，增加I/O开销。
2. **预读取（Prepaging）**：**提前将页面引入到内存中**
   - **原理**：在页面故障发生时，**不仅加载当前需要的页面，还加载相邻的页面**。
   - **优点**：提高I/O效率，**减少因页面故障导致的中断**。
   - **缺点**：基于预测，如果加载的页面很少被访问，则效率较低。
   - **适用场景**：适用于加载页面时。

### 页面置换策略
页面置换策略的目标是**降低页面故障率，确保常用页面保留在内存中，同时减少页面置换的延迟**。

流程如下：

1. 在磁盘上**查找页面的位置**
2. 查找免费的 page frame
   1. 如果有**免费的 page frame，则使用它**
   2. 否则，使用页面替换算法选择 受害 frame
   3. 如有必要，将所选页面**写入磁盘并更新任何必要的表**
3. 从磁盘**读取请求的页面**。
4. 重新启动用户进程。



先补充一些概念：

- **Reference  String**：被引用的页面序列。
- 示例：如果用户具有以下地址序列：
  - 123, 215, 600, 1234, 76, 96
  - 如果页面大小为 100，则引用字符串为：1、2、6、12、0、0
- 一般通过在 Reference  String  运行页面替换算法，评估性能，一般是**通过计算 Reference  String 上的页面错误数**。



以下是几种常见的页面置换算法：

#### 1. 最优置换算法（Optimal Algorithm）
- **原理**：选择**将来最长时间内不会被访问的页面进行置换**。

- **特点**：理论上最优，但需要知道未来的页面访问序列，实际中无法实现。

  若已经知道未来的页面访问序列，则**不应使用需求获取 ，应使用预分页，以允许分页与计算重叠**

- **用途**：作为其他算法的性能比较基准。

  ![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505261930838.webp)

#### 2. 随机置换算法（Random Algorithm）
- **原理**：随机选择一个页面进行置换。
- **特点**：简单易实现，但性能较差。

#### 3. 先进先出置换算法（FIFO, First-In First-Out）
- **原理**：选择最早进入内存的页面进行置换。
- **实现**：维护一个页面队列，队首页面最先被置换。按顺序，他们进入内存时，最旧的页面位于列表的前面。
- **优点**：**实现简单。**
- **缺点**：**可能导致重要页面（如内存最长，经常使用）被置换，且存在Belady异常**（增加页面框数量反而增加页面故障率）。

![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505261936450.webp)

> ### **Belady 异常（Belady's Anomaly）**  
> **Belady 异常**是指在使用某些页面置换算法（Page Replacement Algorithms）时，**增加分配的物理内存页框（Page Frames）数量，反而导致缺页次数（Page Faults）增加**的现象。这种现象违背了直觉，因为通常认为更多的内存应该能减少缺页。  
>
> ---
>
> ### **1. 为什么会发生 Belady 异常？**
> Belady 异常通常发生在**先进先出（FIFO）页面置换算法**中，但不会发生在**最优置换（OPT）** 或 **最近最少使用（LRU）** 算法上。  
>
> #### **示例（FIFO 导致 Belady 异常）**
> 假设：
> - 页面访问序列：`1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5`
> - 比较两种内存分配情况：
>   - **3 个页框（FIFO）**：缺页次数 = 9 次  
>   - **4 个页框（FIFO）**：缺页次数 = 10 次（反而比 3 个页框时更差！）  
>
> **原因**：
>
> - FIFO 算法**可能会过早地替换掉未来仍会被频繁访问的页面，而增加内存后，这种替换策略反而导致更差的缓存命中率**。
>
> ---
>
> ### **2. 哪些算法会出现 Belady 异常？**
> | 算法                    | 是否会出现 Belady 异常？ |
> | ----------------------- | ------------------------ |
> | **FIFO（先进先出）**    | ✅ 会出现                 |
> | **OPT（最优置换）**     | ❌ 不会出现               |
> | **LRU（最近最少使用）** | ❌ 不会出现               |
> | **Clock（近似 LRU）**   | ❌ 不会出现               |
>
> **关键点**：
> - **FIFO 算法** 无法考虑页面的未来访问情况，导致 Belady 异常。
> - **LRU 和 OPT** 基于访问历史或未来需求，因此不会出现该问题。
>
> ---
>
> ### **3. 如何避免 Belady 异常？**
> 1. **改用 LRU 或近似 LRU（如 Clock 算法）**：  
>    - LRU 基于“最近使用”原则，不会因增加内存而增加缺页。
> 2. **使用工作集模型（Working Set Model）**：  
>    - 动态调整分配给进程的页框数量，避免固定分配导致异常。
> 3. **避免纯 FIFO 策略**：  
>    - 可以结合 FIFO 和 LRU 的思想（如 Second-Chance 算法）。
>
> ---
>
> ### **4. 现实中的影响**
> - **操作系统设计**：现代 OS（如 Linux、Windows）通常使用 **LRU 近似算法**（如 Clock），避免 Belady 异常。
> - **数据库缓存管理**：数据库（如 MySQL 的 Buffer Pool）通常采用 LRU 变体，防止缓存效率下降。
>
> ---
>
> ### **总结**
> Belady 异常揭示了**“更多内存 ≠ 更高性能”**的特殊情况，强调了页面置换算法选择的重要性。**FIFO 算法** 是其主要“肇事者”，而 **LRU 和 OPT** 则能避免该问题。在设计和优化内存管理时，应优先选择更智能的置换策略。

#### 4. 第二次机会算法（Second Chance Algorithm）
- **原理**：对FIFO算法的改进，**检查页面的引用位（R bit），如果为1，则将其置为0并移到队尾；如果为0，则置换该页面**。

  即每个页面都有两条命，复活后地位上升。

- **特点**：避免了FIFO算法中可能置换重要页面的问题。

  ![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505262001180.webp)

#### 5. 时钟算法（Clock Algorithm）
- **原理**：基于第二次机会算法的改进，**使用循环链表模拟页面队列**，通过指针移动实现页面置换。

- **实现**：当页面故障发生时，**检查指针指向的页面的引用位，若为0则置换，若为1则将其置为0并移动指针**。

- **优点**：**实现简单且高效。**

- **示例**：

  ![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505262004099.webp)

  ![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505262005109.webp)

#### 6. NRU 算法（Not Recently Used Page Replacement）

- **原理**：选择**最近未被使用的页面**进行置换。
- **实现**：
  - 每个页面设置一个引用位 R 和修改位 M，位在页面被引用时（最近读取或者写入）、修改（写入）时设置
  - **当进程启动时，所有页面的 R 和 M 初始化为0。**
  - **定期清理 R 位，即设置 R 位为0。**
- 页面分类：R 前 M 后
  - 第 0 类：未引用，未修改 
  - 第 1 类：未引用，已修改 
  - 第 2 类：已引用，未修改 
  - 第 3 类：已引用、已修改
- **从编号最低的非空类中，随机删除页面**

#### 7. 最近最少使用算法（LRU, Least Recently Used）
- **原理**：选择**最长时间未被访问的页面**进行置换。

- **实现**：
  
  - **软件实现**：维护一个页面的链表，每次访问页面时更新链表顺序，**将最近访问的页面移到链表头部，最少的在尾部，缺点是每个引用都需要更新该列表，花销高。**
  
  - **硬件实现**：使用计数器或矩阵记录页面的访问时间，选择访问时间最早的页面进行置换。
  
    - 方案1：**为硬件配备 64 位计数器**（即记录每个页面的最近引用时间，时间最远的页面删除）
  
      1. 在每条指令之后递增。
      2. 在内存引用之后，**计数器的值存储在刚刚引用的页面的页表条目中****，即最近引用时间索引编号。**
      3. **选择具有最低值计数器的页面**
      4. **定期将计数器归零**
  
    - 方案2：为具有 $n$ 个页帧的计算机维护一个 $n \times n$ 位的矩阵。行 K 为 1，列 K 为 0。
  
      **引用页帧 $K$ 时**：
  
      1. 将行 $K$ 设置为全 1。
      2. 将列 $K$ 设置为全 0。
  
      **二进制最小的行时 LRU 页。**
  
- **特点**：性能较好，但实现复杂。

  ![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505262022942.webp)

#### 8. 不经常使用算法（NFU, Not Frequently Used）
- **原理**：选择**使用频率最低的页面进行置换**。即模拟 LRU 算法，这里**维护的是引用次数，而不是引用时间**。
- **实现**：在每个时钟中断时，**将页面的引用位加到与其关联的计数器中，页面故障时选择计数器最低的页面进行置换。**
- **缺点**：**无法忘记很久以前的页面访问，可能导致误置换**。

#### 9. 老化算法（Aging Algorithm）
- **原理**：对NFU算法的改进，通过右移计数器并添加当前引用位，给予最近的页面访问更高的优先级。
- **实现**：在每个时钟中断时，**将计数器右移一位，并将引用位加到计数器的最高位**。
- **优点**：更好地模拟LRU算法，避免了NFU算法的缺点。

> ### **传统 NFU（Not Frequently Used）算法及其问题**  
>
> #### **1. 传统 NFU 算法原理**  
> NFU（Not Frequently Used）是一种基于**页面访问频率**的页面置换算法，核心思想是：  
> - **每个页面维护一个计数器**，记录其被访问的次数。  
> - 当需要置换页面时，**选择计数器值最小的页面**（即“最不频繁使用”的页面）进行替换。  
>
> **实现方式**：  
> - 每次访问页面时，其计数器 +1。  
> - 缺页时，扫描所有页面的计数器，选择计数值最小的替换。  
>
> ---
>
> #### **2. 传统 NFU 的问题**  
> 尽管 NFU 看起来合理，但它存在几个严重问题：  
>
> ##### **（1）缺乏时间局部性考虑（Aging Problem）**  
> - NFU **只统计历史访问次数**，但无法区分“最近频繁访问”和“很久以前频繁访问”的页面。  
> - 例如：
>   - 页面 A 在过去被大量访问，但最近不再使用，它的计数值仍然很高，导致无法被置换。  
>   - **页面 B 最近被频繁访问，但历史访问较少，可能被错误地换出**。  
>
> ##### **（2）计数器无限增长**  
> - 计数器只增不减，长期运行的系统中，某些页面的计数值可能变得极大，导致算法退化。  
> - 例如：一个早期频繁访问的页面，即使后来不再使用，也可能因为历史计数值高而长期驻留内存。  
>
> ##### **（3）性能开销**  
> - **每次缺页时，需要遍历所有页面的计数器，时间复杂度较高（O(n)）**。  
>
> ---
>
> ### **改进的 NFU 算法：Aging NFU（老化 NFU）**  
> 为了解决传统 NFU 的问题，研究者提出了 **Aging NFU（老化 NFU）**，主要改进点：  
>
> #### **1. Aging NFU 的核心思想**  
> - **定期右移计数器（模拟老化）**：  
>   - 每隔固定时间（如每个时钟中断），所有页面的计数器 **右移 1 位（相当于除以 2）**。  
>   - 这样，**历史访问记录会随时间衰减**，**最近访问的页面权值更高**。  
> - **访问时设置最高位**：  
>   - 每次页面被访问时，**其计数器最高位 +1**（例如 8 位计数器，访问时 +128）。  
>
> #### **2. Aging NFU 的工作流程**  
> 1. **初始化**：所有页面的计数器 = 0。  
> 2. **访问页面**：  
>    - 若页面被访问，则 **最高位 +1**（如 `counter += 0b10000000`）。  
> 3. **定期老化**：  
>    - 每隔 Δt 时间，所有计数器 **右移 1 位**（如 `counter >>= 1`）。  
> 4. **页面置换**：  
>    - 缺页时，选择 **计数值最小的页面** 替换。  
>
> #### **3. Aging NFU 的优势**  
> ✅ **解决 Aging Problem**：  
>    - 老页面计数值会随时间衰减，最近访问的页面更可能保留。  
> ✅ **避免计数器无限增长**：  
>    - 右移操作让计数器保持在一定范围内。  
> ✅ **更接近 LRU 行为**：  
>    - 由于最近访问的页面计数值较高，Aging NFU 比传统 NFU 更接近 LRU 的效果。  
>
> #### **4. Aging NFU 的局限性**  
> - **仍然不是真正的 LRU**：  
>   - 由于采用近似统计，可能不如 LRU 精确。  
> - **参数敏感**：  
>   - 老化间隔（Δt）和计数器位数需要合理设置，否则可能影响性能。  
>
> ---
>
> ### **对比：NFU vs. Aging NFU vs. LRU**  
> | 算法          | 是否考虑时间局部性 | 计数器是否衰减 | 计算复杂度 | 近似 LRU 程度 |
> | ------------- | ------------------ | -------------- | ---------- | ------------- |
> | **传统 NFU**  | ❌ 否               | ❌ 否           | O(n)       | 较差          |
> | **Aging NFU** | ✅ 是               | ✅ 是           | O(n)       | 较好          |
> | **LRU**       | ✅ 是               | -              | O(1)~O(n)  | 精确          |
>
> ---
>
> ### **总结**
> - **传统 NFU** 简单但存在严重老化问题，不适合实际系统。  
> - **Aging NFU** 通过定期右移计数器模拟老化，更合理，但仍不如 LRU 精确。  
> - **现代系统** 通常使用 **Clock 算法（近似 LRU）** 或 **工作集模型**，而非纯 NFU。  
>
> Aging NFU 是早期内存管理的重要改进，为后来的近似 LRU 算法（如 Linux 的 **二次机会法**）提供了理论基础。

![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505262031202.webp)

#### 10. 工作集算法（Working Set Algorithm）
- **原理**：**工作集是指进程在过去一段时间内访问过的页面集合。选择不在工作集中的页面进行置换。**
  - $W(k,t)$ 是时间 $t$ 时的工作集
  - 或者 $W(t, \Delta)$ 表示是时间 $[t-\Delta,t]$内的工作集。

- **实现**：记录页面的**引用时间和访问频率，选择最长时间未被访问且不在工作集中的页面进行置换**。
- **特点**：能够较好地反映进程的局部性特征，但实现复杂。

1. **在每一个时钟刻，清除所有的 R 位。**
2. 在寻找候选的替换页面时，扫描物理内存中的所有页面。
   - 如果为 R = 1：保存时间 $t$ 到 PTE 中的 LTU （Last time used）中。
   - 如果 $(t - LTU) > \tau$，移除该页面
   - 如果 $(t -LRU) \leq \tau$，记录拥有最大年龄的 page
   - age = current virtual time - last time used

![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505262036332.webp)

![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505262109898.webp)

#### 11. 工作集时钟算法（WSClock Algorithm）
- **原理**：基于时钟算法和工作集算法的结合，**使用循环链表和工作集信息进行页面置换**。

- **实现**：在页面故障时，检查指针**指向的页面的引用位和时间戳，选择合适的页面进行置换**。

- **优点**：简单高效，广泛使用。

- 工作流程：

  - 遇到 page fault
  - 如果 R=1，设置 R=0，且指针前移，继续寻找
  - 如果 R=0
    - 如果 $age \leq \tau$，**指针前移，继续寻找**
    - 如果 $age > \tau$ 且 clean，**则清空它**
    - 如果 $age > \tau$ 且为脏，**则调用磁盘写，然后指针前移，继续寻找**

  - 如果重新回到了起点：
    - 如果已经执行了一次写入，则遇到的第一个干净的页面将被移除
    - 如果没有执行任何写入（即所有页面都在工作集中）：
      - 寻找任何干净的页面并使用
      - 如果不存在干净的页面，选择当前的页面并写回到磁盘中

- **例子**：

  ![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505262141974.webp)

  ![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505262141288.webp)

> ### **工作集页面置换算法（Working Set Page Replacement Algorithm）**
>
> 工作集（Working Set）模型由 **Peter Denning** 在 1960 年代提出，用于描述进程在某一时间段内**活跃访问的页面集合**。工作集页面置换算法基于该理论，目标是**确保进程的工作集常驻内存**，以减少缺页中断（Page Faults），提高系统性能。
>
> ---
>
> ## **1. 工作集（Working Set）的定义**
> - **工作集** $ W(t, \tau) $ 是指在时间窗口 $ \tau $ 内，进程访问的**不同页面的集合**。  
>   - $ t $：当前时间  
>   - $ \tau $：工作集窗口大小（如最近 10000 次内存访问）  
> - **示例**：  
>   - 若进程在过去 $ \tau $ 时间内访问了页面 {A, B, C}，则其工作集为 {A, B, C}。  
>   - 如果某个页面在 $ \tau $ 时间内未被访问，则它不在工作集中。
>
> ---
>
> ## **2. 工作集页面置换算法**
> 工作集算法的主要思想：
> 1. **跟踪每个进程的工作集**，确保工作集中的页面尽量保留在内存中。  
> 2. **缺页时，优先置换不在工作集中的页面**。  
>
> ### **（1）基本工作集置换算法**
> **步骤**：
> 1. 维护一个**滑动时间窗口 $ \tau $**（如最近 10,000 次内存访问）。  
> 2. 对于每个页面，记录它**最近是否在 $ \tau $ 时间内被访问过**。  
> 3. 当发生缺页时：
>    - **如果内存未满**，直接加载新页面。  
>    - **如果内存已满**，选择一个**不在工作集（即最近 $ \tau $ 时间内未访问）的页面**置换出去。  
>    - 如果没有这样的页面，则选择**最久未被访问的页面（类似 LRU）**。
>
> **示例**：
> - 假设 $ \tau = 3 $（最近 3 次访问）：
>   - 访问序列：A, B, A, C, D  
>   - 当前工作集（最后 3 次）：{A, C, D}  
>   - 若需置换，优先选择不在 {A, C, D} 的页面（如 B）。
>
> ---
>
> ### **（2）改进：工作集时钟算法（WSClock）**
> 由于严格的工作集算法实现成本较高，实际系统（如 UNIX）通常采用 **WSClock**（工作集时钟算法），结合了 **Clock 算法** 和 **工作集模型**。
>
> **实现方式**：
> 1. 维护一个**环形链表（类似 Clock 算法）**，每个页面存储：
>    - **最近访问时间（R）**  
>    - **引用位（Reference Bit）**  
> 2. 当缺页发生时：
>    - 扫描环形链表，检查页面是否在**工作集窗口 $ \tau $** 内被访问过：
>      - **如果在 $ \tau $ 内访问过（R=1）**：保留，并清除 R 位。  
>      - **如果不在 $ \tau $ 内（R=0）**：置换该页面。  
>    - 如果转完一圈仍未找到可置换的页面，则**扩展 $ \tau $ 或强制置换最旧的页面**。
>
> **优点**：
> - 比纯工作集算法更高效（近似计算）。  
> - 适用于实际操作系统（如 Linux 的页面置换策略类似 WSClock）。
>
> ---
>
> ## **3. 工作集算法的特点**
> ### **（1）优点**
> ✅ **减少缺页率**：通过确保活跃页面常驻内存，降低缺页中断。  
> ✅ **适应程序局部性**：符合“程序在一段时间内集中访问部分页面”的规律。  
> ✅ **防止抖动（Thrashing）**：通过动态调整工作集，避免内存过载导致的频繁置换。  
>
> ### **（2）缺点**
> ❌ **计算开销较大**：严格的工作集算法需要维护访问历史，可能影响性能。  
> ❌ **窗口大小 $ \tau $ 的选择敏感**：
>    - $ \tau $ 太小 → 工作集不能完整覆盖活跃页面，仍会缺页。  
>    - $ \tau $ 太大 → 内存中保留过多无用页面，浪费资源。  
>
> ---
>
> ## **4. 工作集 vs. 其他页面置换算法**
> | 算法        | 核心思想                     | 是否动态适应 | 计算复杂度 | 适用场景               |
> | ----------- | ---------------------------- | ------------ | ---------- | ---------------------- |
> | **FIFO**    | 置换最早进入的页面           | ❌ 否         | O(1)       | 简单但存在 Belady 异常 |
> | **LRU**     | 置换最久未使用的页面         | ✅ 是         | O(n)       | 理想但实现成本高       |
> | **Clock**   | 近似 LRU，使用引用位         | ✅ 是         | O(1)       | 实际操作系统常用       |
> | **工作集**  | 保留最近 $ \tau $ 访问的页面 | ✅ 是         | O(n)       | 适合防止抖动           |
> | **WSClock** | 工作集 + Clock 结合          | ✅ 是         | O(1)       | 现代操作系统优化方案   |
>
> ---
>
> ## **5. 实际应用**
> - **UNIX/Linux**：采用类似 WSClock 的策略（结合 LRU 近似和工作集思想）。  
> - **Windows**：使用工作集管理进程内存，并结合 Clock 算法进行置换。  
> - **数据库系统**：如 Oracle 的 Buffer Pool 使用工作集模型优化查询缓存。  
>
> ---
>
> ## **总结**
> - **工作集算法** 通过跟踪进程的活跃页面集合，减少缺页，适用于**长时间运行的进程**。  
> - **严格的工作集算法** 计算成本高，因此 **WSClock** 是更实用的优化版本。  
> - 现代操作系统通常**结合工作集、Clock 和 LRU 近似算法**，以平衡性能和开销。  
>
> 工作集模型是**防止内存抖动（Thrashing）** 的关键技术之一，对虚拟内存管理影响深远。

### 页面置换算法的性能比较
- **最优算法**：理论上最优，但无法实现。可作为比较衡量的标准。
- **随机算法**：性能较差。
- **FIFO算法**：简单但存在Belady异常。
- **第二次机会算法**：改进了FIFO算法，避免了重要页面被置换。
- **时钟算法**：高效且实现简单。
- **LRU算法**：性能较好，但实现复杂。
- **NFU和老化算法**：对LRU算法的近似实现，性能较好。
- **工作集算法和WSClock算法**：能够较好地反映进程的局部性特征，性能较好。

![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505262144149.webp)







## 分段（Segmentation）

分段是一种内存管理技术，将**程序划分为多个逻辑段，每个段可以独立地分配和管理内存**。

### 分段的优点
1. **灵活性**：每个段可以**独立地增长或缩小，便于动态内存分配**。
2. **保护机制**：可以为每个段设置不同的访问权限，**提高内存保护的安全性**。
3. **代码共享**：便于多个进程共享同一个代码段，**提高内存利用率**。
4. **链接和共享**：**便于程序的链接和共享，简化了程序的开发和维护**。

### 分段的缺点
1. **碎片问题**：类似于交换系统，分段可能**导致内存碎片化，浪费内存空间**。
2. **管理复杂**：分段管理需要**维护多个段表和页面表，增加了内存管理的复杂性**。
3. **段大小限制**：某些段可能过大，无法完全装入物理内存。

## 分段与分页的结合（Segmentation with Paging）
分段与分页的结合是一种混合内存管理技术，**将程序划分为多个段，每个段再划分为多个页面**。这种技术结合了分段和分页的优点，既提供了分段的灵活性和保护机制，又利用了分页的内存管理效率。

### 实现方式
1. **段表和页面表**：**每个进程维护一个段表，段表中的每个条目指向一个页面表，页面表中的每个条目指向一个物理页面框**。
2. **地址转换**：逻辑地址由**段号、页号和页内偏移组成**，通过段表和页面表将逻辑地址转换为物理地址。

### 优点
1. **灵活性**：每个段可以独立地分配和管理内存，便于动态内存分配。
2. **保护机制**：可以为每个段设置不同的访问权限，提高内存保护的安全性。
3. **代码共享**：便于多个进程共享同一个代码段，提高内存利用率。
4. **内存管理效率**：利用分页技术，减少了内存碎片化问题，提高了内存管理的效率。

### 缺点
1. **管理复杂**：需要维护多个段表和页面表，增加了内存管理的复杂性。
2. **段大小限制**：某些段可能过大，无法完全装入物理内存。

## 分页系统的设计问题（Design Issues for Paging Systems）

本地分配策略和全局分配策略：**本地分配和全局分配的策略不同**，导致替换的结果也不同。

![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505262352901.webp)



### （一）页面大小的选择
- **小页面**：
  - **优点**：**减少内部碎片，提高内存利用率**。
  - **缺点**：**增加页表大小，增加管理开销**。
- **大页面**：
  - **优点**：**减少页表大小，降低管理开销**。
  - **缺点**：**增加内部碎片，可能导致内存浪费**。

### （二）本地与全局分配策略（Local vs. Global Allocation Policies）
- **本地策略**：每个进程**根据自身的页面故障率动态调整分配的页面框数量**。
- **全局策略**：系统**根据全局页面故障率动态调整所有进程的页面框分配**。

### （三）负载控制（Load Control）
- **问题**：即使设计良好，系统仍可能因**进程过多**而发生抖动（Thrashing）。
- **解决方案**：
  1. **减少竞争内存的进程数量**。
  2. **将某些进程交换到磁盘，重新分配其占用的页面框**。
  3. 调整**多编程程度**（Degree of Multiprogramming）。

## 页面大小（Page Size）
### 优势
- **减少内部碎片**：小页面可以减少内存中未使用的程序部分，从而降低内部碎片。
- **提高内存利用率**：小页面使得内存分配更加灵活，减少了因页面过大而导致的内存浪费。

### 劣势
- **增加页表大小**：程序需要更多页面，导致页表变大，增加了内存管理的复杂性。
- **增加管理开销**：页表的大小和管理开销会随着页面数量的增加而增加。

### 页表和内部碎片的开销
- **公式**：
  $$
  \text{Overhead} = \frac{s \cdot e}{p} + \frac{p}{2}
  $$
  
  - $ s $：平均进程大小（字节）
  - $ p $：页面大小（字节）
  - $ e $：页表条目大小（字节）
  
- **优化条件**：当 $ P = \sqrt{2se} $ 时，开销最小化。

- **示例**：若 $ S = 1MB $，$ e = 8 $，$ P = 4KB $，则开销最小。

> 在操作系统中，**页面大小的开销（Page Size Overhead）** 主要涉及 **内存浪费（内部碎片）** 和 **页表开销**。以下是计算页面大小相关开销的核心公式及分析：
>
> ---
>
> ### **1. 内部碎片（Internal Fragmentation）开销**
> **定义**：进程分配的最后一页可能未被完全利用，导致内存浪费。  
> **计算公式**：  
> $$
> \text{平均内部碎片} = \frac{\text{页面大小}}{2}
> $$
> **推导**：  
> - 假设进程大小均匀分布，最后一页的平均浪费空间是页面大小的一半。  
> - 例如，页面大小 = 4KB，则平均每个进程浪费 2KB。
>
> ---
>
> ### **2. 页表（Page Table）开销**
> **定义**：页表存储虚拟页到物理页框的映射，占用内存空间。  
> **计算公式**：  
> $$
> \text{页表大小} = \text{进程地址空间大小} \times \frac{\text{页表项大小}}{\text{页面大小}}
> $$
> **变量说明**：  
> - **页表项大小**：通常 4~8 字节（含标志位、物理页框号等）。  
> - **进程地址空间大小**：如 32 位系统 = \( $2^{32}$ \) 字节。  
>
> **示例**：  
> - 页面大小 = 4KB，页表项 = 8B，32 位地址空间：  
>   $$
>   \text{页表大小} = 2^{32} \times \frac{8}{2^{12}} = 8 \text{MB}
>   $$
> - 若页面大小增大到 8KB，页表大小减半为 4MB。
>
> ---
>
> ### **3. 总开销（Trade-off）优化**
> 页面大小的选择需要平衡 **内部碎片** 和 **页表开销**：  
> $$
> \text{总开销} = \left( \frac{\text{平均进程内存占用}}{\text{页面大小}} \times \text{页表项大小} \right) + \left( \frac{\text{页面大小}}{2} \times \text{进程数} \right)
> $$
> **优化目标**：  
> - **大页面** → 减少页表大小，但增加内部碎片。  
> - **小页面** → 减少内部碎片，但页表膨胀。  
>
> ---
>
> ### **4. 其他影响因素**
> #### **（1）TLB 命中率**
> - **页面越大，TLB 覆盖的地址范围越大，可能提高命中率。**  
> - 但过大的页面会导致 TLB 条目减少，反而降低命中率。  
>
> #### **（2）I/O 效率**
> - 大页面减少磁盘 I/O 次数（缺页时读取更多数据）。  
> - 但传输大页面可能增加延迟。  
>
> #### **（3）多线程共享**
> - 大页面减少共享内存的页表项，但可能引发 **假共享（False Sharing）**。
>
> ---
>
> ### **5. 实际系统中的典型值**
> | 系统类型               | 典型页面大小 | 选择原因                    |
> | ---------------------- | ------------ | --------------------------- |
> | 通用系统（Linux/x86）  | 4KB          | 平衡碎片和页表开销          |
> | 大页支持（Huge Pages） | 2MB/1GB      | 减少 TLB 缺失，适合数据库等 |
> | 嵌入式系统             | 1KB~4KB      | 节省内存，适应小内存设备    |
>
> ---
>
> ### **总结**
> - **内部碎片开销** ≈ 页面大小/2（每进程）。  
> - **页表开销** ≈ 地址空间 × (页表项大小/页面大小)。  
> - **最佳页面大小**需权衡：  
>   - **小页面**：**减少碎片，增加页表/TLB 压力。**  
>   - **大页面**：**减少页表/TLB 压力，但浪费内存**。  
>
> 现代系统通过 **多级页表** 和 **大页（Huge Pages）** 优化开销。例如，Linux 默认使用 4KB 页，但允许进程申请 2MB 或 1GB 大页以减少 TLB 缺失。

## 指令和数据空间分离（Separate Instruction and Data Spaces）
- **单地址空间**：传统的内存管理方式，指令和数据共享一个地址空间。
- **分离地址空间**：将指令和数据空间分开，可以提高内存管理的效率和安全性。
- **优势**：
  - **方便共享**：指令和数据可以分别存储在不同的页面中，**便于多个进程共享**。
  - **提高安全性**：可以对指令和数据分别设置访问权限，**防止非法访问**。
  
  ![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505270939819.webp)

## 共享页面（Shared Pages）
- **共享机制**：**多个进程可以共享同一个程序的页面表，从而减少内存占用**。
- **实现方式**：通过进程表和页面表的共享，实现多个进程对同一程序的访问。
- **优势**：
  - **节省内存**：减少了重复加载相同程序的内存开销。
  - **提高效率**：多个进程可以同时访问同一个程序，**提高了系统的运行效率**。
  
  ![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505270941105.webp)

## 清理策略（Cleaning Policy）
- **背景进程**：需要一个后台进程（分页守护进程）定期检查内存状态。
- **页面替换算法**：当可用的内存帧不足时，选择要替换的页面（不定时），使用类似时钟算法（即使用循环队列）的页面替换算法，但具有差异（front hand & back hand）
- **优势**：
  - 自动管理：后台进程自动管理内存，减少了系统的干预。
  - 提高效率：通过页面替换算法，可以有效地利用有限的内存资源。

## 分页系统的实现问题（Implementation Issues）
- **操作系统与分页的交互**：
  1. **进程创建**：
     - **确定程序大小。**
     - **创建页面表**。
  2. **进程执行**：
     - 为新进程**重置MMU（内存管理单元）**。
     - **清空TLB（转换后备缓冲区）**。
  3. **页面故障时间（缺页）**：
     - **确定导致故障的虚拟地址**。
     - **交换目标页面**，将所需页面加载到内存中。
  4. **进程终止时间**：
     - 释放页面表和页面。

## 页面故障处理（Page Fault Handling）
- **处理步骤**：
  1. **硬件陷阱**：硬件陷入到内核中，将程序计数器（PC）的值保存到堆栈中。
  2. **保存寄存器**：保存通用寄存器的值。
  3. **确定虚拟页面**：操作系统确定需要加载的虚拟页面。
  4. **检查地址有效性**：检查虚拟地址是否有效，并查找页帧。
  5. **处理脏页**：如果所选页帧是脏页（即被修改过），将其写入磁盘，并暂停进程。
  6. **加载新页面**：从磁盘中加载新页面到内存，进程仍然暂停。
  7. **更新页面表**：磁盘中断后，更新页表。
  8. **恢复故障指令**：将故障指令恢复到开始时的状态。
  9. **重新调度进程**：将故障进程重新调度到运行队列中。
  10. **恢复寄存器**：恢复保存的寄存器值。
  11. **继续执行程序**：程序从故障点继续执行。

## 分段（Segmentation）
### 分段的动机
- **虚拟内存解决方案**：分页是一维的，但对于某些应用程序，拥有多个虚拟地址空间可能比只有一个更好。

- **示例**：编译器在编译过程中会构建许多表格，如源文本、符号表、常量表、解析树和堆栈。如果程序的变量数量远大于其他资源，会发生什么？

  ![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505270951553.webp)

  **解决方案：分段**

### 分段的实现

分段是一种内存管理方案，支持用户查看内存。

![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505271002708.webp)

![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505271002328.webp)

- **独立地址空间**：分段提供**多个完全独立的地址空间，称为段**。
- **段的特性**：
  - 每个段可以**独立地增长或缩小**。
  - **段的大小可以动态变化，解决了传统一维地址空间中表格相互冲突的问题**。

### 分段的逻辑视图
- **段表**：逻辑地址由两部分组成：<虚拟段号，偏移>。将二维的，由用户定义的虚拟地址映射到一维的物理地址
  - **虚拟段号用作段表的索引**。
  - 段表中的每个条目包含：
    - **基地址**：段在内存中的起始物理地址。
    - **极限（limit）**：段的长度。
  - **段表基寄存器  Segment-table base register（STBR）**：指向段表在内存中的位置。

### 地址转换
- **逻辑地址到物理地址的转换**：
  - 检查偏移是否小于段的极限。
  - 如果偏移小于极限，计算物理地址 = 段基地址 + 偏移。
  - 如果偏移大于极限，触发地址错误。

![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505271009690.webp)

![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505271009764.webp)

### 分段的优点
- **灵活性**：每个段可以独立地增长或缩小。
- **保护机制**：每个段可以有自己的保护信息，便于实现内存保护。
- **链接和共享**：**程序链接和代码共享变得更加容易，多个进程可以共享同一个代码段**。

### 分段的缺点
- **程序员需要了解内存模型**：在汇编语言级别，程序员需要了解分段的内存模型。
- **碎片问题**：类似于交换系统，分段可能导致内存碎片化，浪费内存空间。
- **段可能过大**：某些段可能太大，无法完全装入物理内存。

![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505271011449.webp)

## 分段与分页的比较（Paging vs. Segmentation）
| 特性                               | 分页（Paging）                           | 分段（Segmentation）                                     |
| ---------------------------------- | ---------------------------------------- | -------------------------------------------------------- |
| 程序员是否需要了解                 | 否                                       | 是                                                       |
| 线性地址空间数量                   | 1                                        | 多个                                                     |
| 总地址空间是否可以超过物理内存大小 | 是                                       | 是                                                       |
| 是否可以区分过程和数据并分别保护   | 否                                       | 是                                                       |
| 是否可以方便地容纳大小变化的表     | 否                                       | 是                                                       |
| 是否便于用户之间共享过程           | 否                                       | 是                                                       |
| 发明目的                           | 提供大线性地址空间，无需购买更多物理内存 | 允许程序被分解为逻辑上独立的地址空间，便于内存共享和保护 |

## 分段与分页的结合（Segmentation with Paging）
- **虚拟内存中的分段，物理内存中的分页**：
  - 段由页面组成。
  - 地址由三部分组成：段号、页号、页内偏移。
  - 物理内存中只包含**一个段需要的部分页面，而不是整个段**。
- **实现方式**：
  - 每个进程需要一个段表。
  - 段表可以**分段和分页**。
  - 段表中的**每个条目指向该段的页面表**，页面表可以是**多级的**。

![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505271014297.webp)

### 地址转换
- **逻辑地址到物理地址的转换**：
  - 检查段表中的极限值，确保偏移小于极限。
  - 如果偏移小于极限，查找段的页面表，将段内偏移转换为物理地址。
  - 如果偏移大于极限，触发地址错误。
  
  ![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505271018842.webp)

### 示例：MULTICS系统

![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505271021092.webp)

- **虚拟地址结构**：
  - 段号：18位
  - 页号：6位
  - 页内偏移：10位
- **段表和页面表**：
  - **段表中的每个条目指向一个页面表**。
  - **页面表中的每个条目指向一个物理页帧**。
- **地址转换过程**：
  - 从虚拟地址中提取段号、页号和页内偏移。
  - 使用段号查找段表，获取段的页面表。
  - 使用页号查找页面表，获取物理页面框架。
  - 将页内偏移加到物理页面框架地址上，得到最终的物理地址。

![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505271023056.webp)

![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505271023118.webp)

![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505271024965.webp)