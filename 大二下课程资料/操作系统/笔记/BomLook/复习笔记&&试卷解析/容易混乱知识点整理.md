以下是几种常见的页面置换算法：

#### 1. 最优置换算法（Optimal Algorithm）

- **原理**：选择**将来最长时间内不会被访问的页面进行置换**。

- **特点**：理论上最优，但需要知道未来的页面访问序列，实际中无法实现。

  若已经知道未来的页面访问序列，则**不应使用需求获取 ，应使用预分页，以允许分页与计算重叠**

- **用途**：作为其他算法的性能比较基准。

  ![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505261930838.webp)

#### 2. 随机置换算法（Random Algorithm）

- **原理**：随机选择一个页面进行置换。
- **特点**：简单易实现，但性能较差。

#### 3. 先进先出置换算法（FIFO, First-In First-Out）

- **原理**：选择最早进入内存的页面进行置换。
- **实现**：维护一个页面队列，队首页面最先被置换。按顺序，他们进入内存时，最旧的页面位于列表的前面。
- **优点**：**实现简单。**
- **缺点**：**可能导致重要页面（如内存最长，经常使用）被置换，且存在Belady异常**（增加页面框数量反而增加页面故障率）。

![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505261936450.webp)

> ### **Belady 异常（Belady's Anomaly）**  
>
> **Belady 异常**是指在使用某些页面置换算法（Page Replacement Algorithms）时，**增加分配的物理内存页框（Page Frames）数量，反而导致缺页次数（Page Faults）增加**的现象。这种现象违背了直觉，因为通常认为更多的内存应该能减少缺页。  
>
> ---
>
> ### **1. 为什么会发生 Belady 异常？**
>
> Belady 异常通常发生在**先进先出（FIFO）页面置换算法**中，但不会发生在**最优置换（OPT）** 或 **最近最少使用（LRU）** 算法上。  
>
> #### **示例（FIFO 导致 Belady 异常）**
>
> 假设：
>
> - 页面访问序列：`1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5`
> - 比较两种内存分配情况：
>   - **3 个页框（FIFO）**：缺页次数 = 9 次  
>   - **4 个页框（FIFO）**：缺页次数 = 10 次（反而比 3 个页框时更差！）  
>
> **原因**：
>
> - FIFO 算法**可能会过早地替换掉未来仍会被频繁访问的页面，而增加内存后，这种替换策略反而导致更差的缓存命中率**。
>
> ---
>
> ### **2. 哪些算法会出现 Belady 异常？**
>
> | 算法                    | 是否会出现 Belady 异常？ |
> | ----------------------- | ------------------------ |
> | **FIFO（先进先出）**    | ✅ 会出现                 |
> | **OPT（最优置换）**     | ❌ 不会出现               |
> | **LRU（最近最少使用）** | ❌ 不会出现               |
> | **Clock（近似 LRU）**   | ❌ 不会出现               |
>
> **关键点**：
>
> - **FIFO 算法** 无法考虑页面的未来访问情况，导致 Belady 异常。
> - **LRU 和 OPT** 基于访问历史或未来需求，因此不会出现该问题。
>
> ---
>
> ### **3. 如何避免 Belady 异常？**
>
> 1. **改用 LRU 或近似 LRU（如 Clock 算法）**：  
>    - LRU 基于“最近使用”原则，不会因增加内存而增加缺页。
> 2. **使用工作集模型（Working Set Model）**：  
>    - 动态调整分配给进程的页框数量，避免固定分配导致异常。
> 3. **避免纯 FIFO 策略**：  
>    - 可以结合 FIFO 和 LRU 的思想（如 Second-Chance 算法）。
>
> ---
>
> ### **4. 现实中的影响**
>
> - **操作系统设计**：现代 OS（如 Linux、Windows）通常使用 **LRU 近似算法**（如 Clock），避免 Belady 异常。
> - **数据库缓存管理**：数据库（如 MySQL 的 Buffer Pool）通常采用 LRU 变体，防止缓存效率下降。
>
> ---
>
> ### **总结**
>
> Belady 异常揭示了**“更多内存 ≠ 更高性能”**的特殊情况，强调了页面置换算法选择的重要性。**FIFO 算法** 是其主要“肇事者”，而 **LRU 和 OPT** 则能避免该问题。在设计和优化内存管理时，应优先选择更智能的置换策略。

#### 4. 第二次机会算法（Second Chance Algorithm）

- **原理**：对FIFO算法的改进，**检查页面的引用位（R bit），如果为1，则将其置为0并移到队尾；如果为0，则置换该页面**。

  即每个页面都有两条命，复活后地位上升。

- **特点**：避免了FIFO算法中可能置换重要页面的问题。

  ![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505262001180.webp)

#### 5. 时钟算法（Clock Algorithm）

- **原理**：基于第二次机会算法的改进，**使用循环链表模拟页面队列**，通过指针移动实现页面置换。

- **实现**：当页面故障发生时，**检查指针指向的页面的引用位，若为0则置换，若为1则将其置为0并移动指针**。

- **优点**：**实现简单且高效。**

- **示例**：

  ![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505262004099.webp)

  ![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505262005109.webp)

#### 6. NRU 算法（Not Recently Used Page Replacement）

- **原理**：选择**最近未被使用的页面**进行置换。
- **实现**：
  - 每个页面设置一个引用位 R 和修改位 M，位在页面被引用时（最近读取或者写入）、修改（写入）时设置
  - **当进程启动时，所有页面的 R 和 M 初始化为0。**
  - **定期清理 R 位，即设置 R 位为0。**
- 页面分类：R 前 M 后
  - 第 0 类：未引用，未修改 
  - 第 1 类：未引用，已修改 
  - 第 2 类：已引用，未修改 
  - 第 3 类：已引用、已修改
- **从编号最低的非空类中，随机删除页面**

#### 7. 最近最少使用算法（LRU, Least Recently Used）

- **原理**：选择**最长时间未被访问的页面**进行置换。

- **实现**：

  - **软件实现**：维护一个页面的链表，每次访问页面时更新链表顺序，**将最近访问的页面移到链表头部，最少的在尾部，缺点是每个引用都需要更新该列表，花销高。**

  - **硬件实现**：使用计数器或矩阵记录页面的访问时间，选择访问时间最早的页面进行置换。

    - 方案1：**为硬件配备 64 位计数器**（即记录每个页面的最近引用时间，时间最远的页面删除）

      1. 在每条指令之后递增。
      2. 在内存引用之后，**计数器的值存储在刚刚引用的页面的页表条目中****，即最近引用时间索引编号。**
      3. **选择具有最低值计数器的页面**
      4. **定期将计数器归零**

    - 方案2：为具有 $n$ 个页帧的计算机维护一个 $n \times n$ 位的矩阵。行 K 为 1，列 K 为 0。

      **引用页帧 $K$ 时**：

      1. 将行 $K$ 设置为全 1。
      2. 将列 $K$ 设置为全 0。

      **二进制最小的行时 LRU 页。**

- **特点**：性能较好，但实现复杂。

  ![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505262022942.webp)

#### 8. 不经常使用算法（NFU, Not Frequently Used）

- **原理**：选择**使用频率最低的页面进行置换**。即模拟 LRU 算法，这里**维护的是引用次数，而不是引用时间**。
- **实现**：在每个时钟中断时，**将页面的引用位加到与其关联的计数器中，页面故障时选择计数器最低的页面进行置换。**
- **缺点**：**无法忘记很久以前的页面访问，可能导致误置换**。

#### 9. 老化算法（Aging Algorithm）

- **原理**：对NFU算法的改进，通过右移计数器并添加当前引用位，给予最近的页面访问更高的优先级。
- **实现**：在每个时钟中断时，**将计数器右移一位，并将引用位加到计数器的最高位**。
- **优点**：更好地模拟LRU算法，避免了NFU算法的缺点。

> ### **传统 NFU（Not Frequently Used）算法及其问题**  
>
> #### **1. 传统 NFU 算法原理**  
>
> NFU（Not Frequently Used）是一种基于**页面访问频率**的页面置换算法，核心思想是：  
>
> - **每个页面维护一个计数器**，记录其被访问的次数。  
> - 当需要置换页面时，**选择计数器值最小的页面**（即“最不频繁使用”的页面）进行替换。  
>
> **实现方式**：  
>
> - 每次访问页面时，其计数器 +1。  
> - 缺页时，扫描所有页面的计数器，选择计数值最小的替换。  
>
> ---
>
> #### **2. 传统 NFU 的问题**  
>
> 尽管 NFU 看起来合理，但它存在几个严重问题：  
>
> ##### **（1）缺乏时间局部性考虑（Aging Problem）**  
>
> - NFU **只统计历史访问次数**，但无法区分“最近频繁访问”和“很久以前频繁访问”的页面。  
> - 例如：
>   - 页面 A 在过去被大量访问，但最近不再使用，它的计数值仍然很高，导致无法被置换。  
>   - **页面 B 最近被频繁访问，但历史访问较少，可能被错误地换出**。  
>
> ##### **（2）计数器无限增长**  
>
> - 计数器只增不减，长期运行的系统中，某些页面的计数值可能变得极大，导致算法退化。  
> - 例如：一个早期频繁访问的页面，即使后来不再使用，也可能因为历史计数值高而长期驻留内存。  
>
> ##### **（3）性能开销**  
>
> - **每次缺页时，需要遍历所有页面的计数器，时间复杂度较高（O(n)）**。  
>
> ---
>
> ### **改进的 NFU 算法：Aging NFU（老化 NFU）**  
>
> 为了解决传统 NFU 的问题，研究者提出了 **Aging NFU（老化 NFU）**，主要改进点：  
>
> #### **1. Aging NFU 的核心思想**  
>
> - **定期右移计数器（模拟老化）**：  
>   - 每隔固定时间（如每个时钟中断），所有页面的计数器 **右移 1 位（相当于除以 2）**。  
>   - 这样，**历史访问记录会随时间衰减**，**最近访问的页面权值更高**。  
> - **访问时设置最高位**：  
>   - 每次页面被访问时，**其计数器最高位 +1**（例如 8 位计数器，访问时 +128）。  
>
> #### **2. Aging NFU 的工作流程**  
>
> 1. **初始化**：所有页面的计数器 = 0。  
> 2. **访问页面**：  
>    - 若页面被访问，则 **最高位 +1**（如 `counter += 0b10000000`）。  
> 3. **定期老化**：  
>    - 每隔 Δt 时间，所有计数器 **右移 1 位**（如 `counter >>= 1`）。  
> 4. **页面置换**：  
>    - 缺页时，选择 **计数值最小的页面** 替换。  
>
> #### **3. Aging NFU 的优势**  
>
> ✅ **解决 Aging Problem**：  
>
>    - 老页面计数值会随时间衰减，最近访问的页面更可能保留。  
>      ✅ **避免计数器无限增长**：  
>    - 右移操作让计数器保持在一定范围内。  
>      ✅ **更接近 LRU 行为**：  
>    - 由于最近访问的页面计数值较高，Aging NFU 比传统 NFU 更接近 LRU 的效果。  
>
> #### **4. Aging NFU 的局限性**  
>
> - **仍然不是真正的 LRU**：  
>   - 由于采用近似统计，可能不如 LRU 精确。  
> - **参数敏感**：  
>   - 老化间隔（Δt）和计数器位数需要合理设置，否则可能影响性能。  
>
> ---
>
> ### **对比：NFU vs. Aging NFU vs. LRU**  
>
> | 算法          | 是否考虑时间局部性 | 计数器是否衰减 | 计算复杂度 | 近似 LRU 程度 |
> | ------------- | ------------------ | -------------- | ---------- | ------------- |
> | **传统 NFU**  | ❌ 否               | ❌ 否           | O(n)       | 较差          |
> | **Aging NFU** | ✅ 是               | ✅ 是           | O(n)       | 较好          |
> | **LRU**       | ✅ 是               | -              | O(1)~O(n)  | 精确          |
>
> ---
>
> ### **总结**
>
> - **传统 NFU** 简单但存在严重老化问题，不适合实际系统。  
> - **Aging NFU** 通过定期右移计数器模拟老化，更合理，但仍不如 LRU 精确。  
> - **现代系统** 通常使用 **Clock 算法（近似 LRU）** 或 **工作集模型**，而非纯 NFU。  
>
> Aging NFU 是早期内存管理的重要改进，为后来的近似 LRU 算法（如 Linux 的 **二次机会法**）提供了理论基础。

![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505262031202.webp)

#### 10. 工作集算法（Working Set Algorithm）

- **原理**：**工作集是指进程在过去一段时间内访问过的页面集合。选择不在工作集中的页面进行置换。**
  - $W(k,t)$ 是时间 $t$ 时的工作集
  - 或者 $W(t, \Delta)$ 表示是时间 $[t-\Delta,t]$内的工作集。

- **实现**：记录页面的**引用时间和访问频率，选择最长时间未被访问且不在工作集中的页面进行置换**。
- **特点**：能够较好地反映进程的局部性特征，但实现复杂。

1. **在每一个时钟刻，清除所有的 R 位。**
2. 在寻找候选的替换页面时，扫描物理内存中的所有页面。
   - 如果为 R = 1：保存时间 $t$ 到 PTE 中的 LTU （Last time used）中。
   - 如果 $(t - LTU) > \tau$，移除该页面
   - 如果 $(t -LRU) \leq \tau$，记录拥有最大年龄的 page
   - age = current virtual time - last time used

![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505262036332.webp)

![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505262109898.webp)

#### 11. 工作集时钟算法（WSClock Algorithm）

- **原理**：基于时钟算法和工作集算法的结合，**使用循环链表和工作集信息进行页面置换**。

- **实现**：在页面故障时，检查指针**指向的页面的引用位和时间戳，选择合适的页面进行置换**。

- **优点**：简单高效，广泛使用。

- 工作流程：

  - 遇到 page fault
  - 如果 R=1，设置 R=0，且指针前移，继续寻找
  - 如果 R=0
    - 如果 $age \leq \tau$，**指针前移，继续寻找**
    - 如果 $age > \tau$ 且 clean，**则清空它**
    - 如果 $age > \tau$ 且为脏，**则调用磁盘写，然后指针前移，继续寻找**

  - 如果重新回到了起点：
    - 如果已经执行了一次写入，则遇到的第一个干净的页面将被移除
    - 如果没有执行任何写入（即所有页面都在工作集中）：
      - 寻找任何干净的页面并使用
      - 如果不存在干净的页面，选择当前的页面并写回到磁盘中

- **例子**：

  ![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505262141974.webp)

  ![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505262141288.webp)

> ### **工作集页面置换算法（Working Set Page Replacement Algorithm）**
>
> 工作集（Working Set）模型由 **Peter Denning** 在 1960 年代提出，用于描述进程在某一时间段内**活跃访问的页面集合**。工作集页面置换算法基于该理论，目标是**确保进程的工作集常驻内存**，以减少缺页中断（Page Faults），提高系统性能。
>
> ---
>
> ## **1. 工作集（Working Set）的定义**
>
> - **工作集** $ W(t, \tau) $ 是指在时间窗口 $ \tau $ 内，进程访问的**不同页面的集合**。  
>   - $ t $：当前时间  
>   - $ \tau $：工作集窗口大小（如最近 10000 次内存访问）  
> - **示例**：  
>   - 若进程在过去 $ \tau $ 时间内访问了页面 {A, B, C}，则其工作集为 {A, B, C}。  
>   - 如果某个页面在 $ \tau $ 时间内未被访问，则它不在工作集中。
>
> ---
>
> ## **2. 工作集页面置换算法**
>
> 工作集算法的主要思想：
>
> 1. **跟踪每个进程的工作集**，确保工作集中的页面尽量保留在内存中。  
> 2. **缺页时，优先置换不在工作集中的页面**。  
>
> ### **（1）基本工作集置换算法**
>
> **步骤**：
>
> 1. 维护一个**滑动时间窗口 $ \tau $**（如最近 10,000 次内存访问）。  
> 2. 对于每个页面，记录它**最近是否在 $ \tau $ 时间内被访问过**。  
> 3. 当发生缺页时：
>    - **如果内存未满**，直接加载新页面。  
>    - **如果内存已满**，选择一个**不在工作集（即最近 $ \tau $ 时间内未访问）的页面**置换出去。  
>    - 如果没有这样的页面，则选择**最久未被访问的页面（类似 LRU）**。
>
> **示例**：
>
> - 假设 $ \tau = 3 $（最近 3 次访问）：
>   - 访问序列：A, B, A, C, D  
>   - 当前工作集（最后 3 次）：{A, C, D}  
>   - 若需置换，优先选择不在 {A, C, D} 的页面（如 B）。
>
> ---
>
> ### **（2）改进：工作集时钟算法（WSClock）**
>
> 由于严格的工作集算法实现成本较高，实际系统（如 UNIX）通常采用 **WSClock**（工作集时钟算法），结合了 **Clock 算法** 和 **工作集模型**。
>
> **实现方式**：
>
> 1. 维护一个**环形链表（类似 Clock 算法）**，每个页面存储：
>    - **最近访问时间（R）**  
>    - **引用位（Reference Bit）**  
> 2. 当缺页发生时：
>    - 扫描环形链表，检查页面是否在**工作集窗口 $ \tau $** 内被访问过：
>      - **如果在 $ \tau $ 内访问过（R=1）**：保留，并清除 R 位。  
>      - **如果不在 $ \tau $ 内（R=0）**：置换该页面。  
>    - 如果转完一圈仍未找到可置换的页面，则**扩展 $ \tau $ 或强制置换最旧的页面**。
>
> **优点**：
>
> - 比纯工作集算法更高效（近似计算）。  
> - 适用于实际操作系统（如 Linux 的页面置换策略类似 WSClock）。
>
> ---
>
> ## **3. 工作集算法的特点**
>
> ### **（1）优点**
>
> ✅ **减少缺页率**：通过确保活跃页面常驻内存，降低缺页中断。  
> ✅ **适应程序局部性**：符合“程序在一段时间内集中访问部分页面”的规律。  
> ✅ **防止抖动（Thrashing）**：通过动态调整工作集，避免内存过载导致的频繁置换。  
>
> ### **（2）缺点**
>
> ❌ **计算开销较大**：严格的工作集算法需要维护访问历史，可能影响性能。  
> ❌ **窗口大小 $ \tau $ 的选择敏感**：
>
>    - $ \tau $ 太小 → 工作集不能完整覆盖活跃页面，仍会缺页。  
>    - $ \tau $ 太大 → 内存中保留过多无用页面，浪费资源。  
>
> ---
>
> ## **4. 工作集 vs. 其他页面置换算法**
>
> | 算法        | 核心思想                     | 是否动态适应 | 计算复杂度 | 适用场景               |
> | ----------- | ---------------------------- | ------------ | ---------- | ---------------------- |
> | **FIFO**    | 置换最早进入的页面           | ❌ 否         | O(1)       | 简单但存在 Belady 异常 |
> | **LRU**     | 置换最久未使用的页面         | ✅ 是         | O(n)       | 理想但实现成本高       |
> | **Clock**   | 近似 LRU，使用引用位         | ✅ 是         | O(1)       | 实际操作系统常用       |
> | **工作集**  | 保留最近 $ \tau $ 访问的页面 | ✅ 是         | O(n)       | 适合防止抖动           |
> | **WSClock** | 工作集 + Clock 结合          | ✅ 是         | O(1)       | 现代操作系统优化方案   |
>
> ---
>
> ## **5. 实际应用**
>
> - **UNIX/Linux**：采用类似 WSClock 的策略（结合 LRU 近似和工作集思想）。  
> - **Windows**：使用工作集管理进程内存，并结合 Clock 算法进行置换。  
> - **数据库系统**：如 Oracle 的 Buffer Pool 使用工作集模型优化查询缓存。  
>
> ---
>
> ## **总结**
>
> - **工作集算法** 通过跟踪进程的活跃页面集合，减少缺页，适用于**长时间运行的进程**。  
> - **严格的工作集算法** 计算成本高，因此 **WSClock** 是更实用的优化版本。  
> - 现代操作系统通常**结合工作集、Clock 和 LRU 近似算法**，以平衡性能和开销。  
>
> 工作集模型是**防止内存抖动（Thrashing）** 的关键技术之一，对虚拟内存管理影响深远。

### 页面置换算法的性能比较

- **最优算法**：理论上最优，但无法实现。可作为比较衡量的标准。
- **随机算法**：性能较差。
- **FIFO算法**：简单但存在Belady异常。
- **第二次机会算法**：改进了FIFO算法，避免了重要页面被置换。
- **时钟算法**：高效且实现简单。
- **LRU算法**：性能较好，但实现复杂。
- **NFU和老化算法**：对LRU算法的近似实现，性能较好。
- **工作集算法和WSClock算法**：能够较好地反映进程的局部性特征，性能较好。

![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505262144149.webp)





**各类存储放置策略**：

> ### **1. First Fit（首次适应）**
>
> - **原理**：从内存起始位置开始搜索，选择 **第一个足够大** 的空闲分区。
> - **示例**：  
>   空闲分区列表：`[10KB, 30KB, 20KB]`  
>   请求 `15KB` → 分配 `30KB`（第一个满足的分区）
> - **特点**：
>   - **优点**：**简单快速，保留大分区供后续需求。**
>   - **缺点**：可能产生较多外部碎片（**小碎片集中在低地址**）。
> - **适用场景**：通用场景，平衡速度和碎片。
>
> ---
>
> ### **2. Next Fit（下次适应）**
>
> - **原理**：类似首次适应，但从 **上次分配结束的位置** 开始搜索（循环遍历）。
> - **示例**：  
>   上次分配在 `30KB` 分区，空闲列表：`[10KB, 30KB, 20KB]`  
>   请求 `15KB` → 从 `30KB` 后开始搜索，分配 `20KB`。
> - **特点**：
>   - **优点**：**比首次适应更均匀地分布碎片。**
>   - **缺点**：可能**跳过较大的空闲分区**，导致大请求无法满足。
> - **适用场景**：需要**减少低地址碎片**的情况。
>
> ---
>
> ### **3. Best Fit（最佳适应）**
>
> - **原理**：搜索 **最小但足够大** 的空闲分区（满足需求的最小分区）。
> - **示例**：  
>   空闲分区列表：`[10KB, 30KB, 20KB]`  
>   请求 `15KB` → 分配 `20KB`（最接近需求的分区）。
> - **特点**：
>   - **优点**：减少大分区被拆分的次数。
>   - **缺点**：**产生大量微小碎片（需频繁合并），搜索速度慢**（需遍历所有分区）。
> - **适用场景**：内存利用率优先的场景。
>
> ---
>
> ### **4. Worst Fit（最差适应）**
>
> - **原理**：搜索 **最大的空闲分区** 进行分配。
> - **示例**：  
>   空闲分区列表：`[10KB, 30KB, 20KB]`  
>   请求 `15KB` → 分配 `30KB`（最大分区）。
> - **特点**：
>   - **优点**：**减少微小碎片，适合大请求**。
>   - **缺点**：可能耗尽大分区，导致**后续大请求**无法满足。
> - **适用场景**：预期**后续多为小请求**的场景。
>
> ---
>
> ### **5. Quick Fit（快速适应）**
>
> - **原理**：维护 **多个独立链表**，按**常见分区大小分类**（如4KB、8KB等）。
> - **示例**：  
>   预设链表：`4KB链表`、`8KB链表`、`16KB链表`  
>   请求 `5KB` → 直接从 `8KB` 链表分配。
> - **特点**：
>   - **优点**：**分配极快**（O(1)时间复杂度）。
>   - **缺点**：合并碎片复杂，**需额外维护多个链表**。
> - **适用场景**：频繁分配固定大小内存（如操作系统内核）。
>
> ---
>
> ### **策略对比总结**
>
> | 策略          | 搜索方式           | 速度 | 碎片问题     | 适用场景         |
> | ------------- | ------------------ | ---- | ------------ | ---------------- |
> | **First Fit** | 从头搜索第一个满足 | 快   | 中等外部碎片 | 通用             |
> | **Next Fit**  | 从上次位置搜索     | 较快 | 碎片分布均匀 | 避免低地址碎片   |
> | **Best Fit**  | 搜索最小满足分区   | 慢   | 大量微小碎片 | 内存利用率优先   |
> | **Worst Fit** | 搜索最大分区       | 慢   | 保留大分区   | 预期后续多小请求 |
> | **Quick Fit** | 直接匹配预设链表   | 极快 | 合并困难     | 固定大小分配     |
>
> ---
>
> ### **选择建议**
>
> - **追求速度**：`Quick Fit` > `First Fit` > `Next Fit`  
> - **减少碎片**：`Best Fit`（小碎片）或 `Worst Fit`（保留大分区）  
> - **平衡型**：`First Fit` 是大多数系统的默认选择。



### 目录存储方式

- **目录存储**：目录**像普通文件一样存储**，**目录条目包含在数据块中。**
- **目录文件**：是一个**包含目录条目的列表**。
- **文件打开**：文件系统使用路径名定位目录条目，目录条目提供**查找磁盘块所需的信息**（如连续块的磁盘地址、链表的第一个块号或i-Node号）。

### 文件属性的存储位置

- **存储在目录条目中**：

  - **固定大小的条目。**

  - **磁盘地址和属性**都在目录条目中。

  - 例如：MS-DOS/Windows。

    ![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505271945336.webp)

- **存储在单独的数据结构中（如i-Node）**：

  - 目录条目包含**文件名和i-Node号**。

  - i-Node包含**文件属性**。

  - 例如：Unix。

    ![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202505271946160.webp)





### Unix V7文件系统

- **目录条目**：
  - 包含文件名和i-Node号。
  - 文件名最多14个字符。
  - 每个目录条目占用16字节。
- **i-Node结构**：
  - 包含文件属性、直接块地址、单级间接块地址、双级间接块地址和三级间接块地址。
- **文件查找**：
  - 通过路径名逐级查找i-Node。
  - 示例：查找`/usr/ast/mbox`需要多次磁盘读取。





- **临界资源**：**一次只能被一个进程访问的资源**，如硬件设备或软件变量。
- **临界区（Critical Section）**：访问临界资源的**程序部分**。
- **互斥的要求**：

  1. 任何时刻**只有一个进程在临界区**。
  2. 不对CPU速度或数量做假设。
  3. **临界区外的进程不能阻塞其他进程**。
  4. **任何进程不能无限期等待进入临界区**。
