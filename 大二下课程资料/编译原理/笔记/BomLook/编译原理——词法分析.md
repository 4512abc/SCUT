# 编译原理——词法分析

## 词法分析

主要研究词法单元的构成和表示方法

![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202504081155170.webp)

[[/D:/整合/华工/source/images/编译原理——语法分析]]

### **1. Lexeme（词素）**

- **定义**：源代码中**连续的字符序列**，是构成语言的基本“单词”。
- **特点**：
  - 是**具体的字符串片段**，例如：`int`, `x`, `=`, `5`, `;`。
  - 无抽象含义，仅表示原始文本。
- **示例**：
  - 代码 `int x = 5;` 的 Lexeme 序列为：`"int"`, `"x"`, `"="`, `"5"`, `";"`。

---

### **2. Token（词法单元）**

- **定义**：Lexeme 的**抽象分类**，包含类型（Token Type）和可选的属性值（Attribute）。
- **组成**：
  - **Token Type**：预定义的语法类别（如关键字、标识符、运算符）。
  - **Attribute（可选）**：附加信息（如标识符的名称、常量的值）。
- **示例**：
  - Lexeme `"int"` → Token: `<KEYWORD, "int">`
  - Lexeme `"x"` → Token: `<IDENTIFIER, "x">`
  - Lexeme `"5"` → Token: `<INTEGER, 5>`

---

### **3. 两者的联系与区别**

| **特性**     | **Lexeme**             | **Token**                            |
| ------------ | ---------------------- | ------------------------------------ |
| **本质**     | 具体的字符序列         | 抽象的分类 + 属性                    |
| **作用**     | 词法分析的输入         | 语法分析的输入                       |
| **抽象层级** | 低（原始文本）         | 高（带语义标签）                     |
| **示例**     | `"if"`, `"123"`, `"+"` | `<IF, ->`, `<NUM, 123>`, `<PLUS, ->` |

- **联系**：
  - Lexeme 是 Token 的**具体实例**，Token 是 Lexeme 的**抽象表示**。
  - 词法分析器（Scanner）将 Lexeme 映射为 Token，供后续语法分析使用。

---

### **4. 实际处理流程**

1. **扫描代码**：
   - 读取流中的字符
   - 将字符组织为连续的 Lexeme（如跳过空格/注释）。
2. **分类映射**：根据语言规则将 Lexeme 转换为 Token。

   - **固定模式**：关键字（`if`）、运算符（`+`）直接匹配 Token 类型。
   - **动态模式**：标识符（变量名）、常量需记录属性值。

3. **输出 Token 序列**：传递给解析器（Parser）构建语法树。

**示例转换**：

```java
if (x > 5) { ... }
```

- **Lexeme 序列**：`"if"`, `"("`, `"x"`, `">"`, `"5"`, `")"`, `"{"`, `"..."`, `"}"`
- **Token 序列**： `<IF, ->`, `<LPAR, ->`, `<ID, "x">`, `<GT, ->`, `<NUM, 5>`, `<RPAR, ->`, `<LBRACE, ->`, `...`, `<RBRACE, ->`

---

### **5. 为什么需要区分两者？**

- **Lexeme** 是词法分析的**原始材料**，关注“是什么字符串”。
- **Token** 是语法分析的**结构化输入**，关注“属于哪类语法单元”。
- **分离意义**：
  - 提高编译器模块化（词法/语法分析解耦）。
  - 简化语法规则（Parser 只需处理 Token 类型，而非具体字符串）。

通过这种分层处理，编译器能高效、准确地解析复杂的源代码结构。

### 词法分析中的挑战

#### **1. 如何确定每个 Token 对应的词素？**

- **问题本质**：词法分析器需要将源代码中的字符序列（Lexeme）分类为抽象的 Token（如关键字、标识符、运算符等）。
- **解决方法**：
  - **预定义规则**：通过正则表达式或有限自动机（DFA）描述每种 Token 的模式（例如 `[a-zA-Z_][a-zA-Z0-9_]*` 匹配标识符）。
  - **优先级匹配**：例如关键字（如 `if`）优先于标识符（如 `ifx`），通过符号表或硬编码规则实现。

#### **2. 当输入存在多种扫描方式时，如何选择？**

- **问题本质**：某些字符序列可能匹配多种词法规则（例如 `>>` 可以是右移运算符或两个 `>` 符号）。
- **解决原则**：
  - **最长匹配原则（Maximal Munch）**：优先选择能匹配的最长字符序列（如 `>>` 视为一个运算符而非两个 `>`）。
  - **上下文相关规则**：结合语法状态（如 C++ 中 `List<List<int>>` 的 `>>` 需特殊处理）。

#### **3. 如何高效解决这些问题？**

- **技术手段**：
  - **有限自动机（DFA）**：将词法规则转换为状态机，实现高效的单遍扫描。
  - **符号表预加载**：提前存储关键字，避免运行时重复匹配。
  - **错误恢复机制**：遇到歧义时，通过恐慌模式（Panic Mode）跳过无效部分，继续分析后续代码。

---

#### **总结**

1. **词素到 Token 的映射**：通过正则表达式/DFA 和优先级规则实现。
2. **歧义处理**：最长匹配优先，必要时结合语法上下文。
3. **效率优化**：DFA、符号表缓存和模块化设计。

这些方法确保了词法分析器在**准确性**（正确分类）和**性能**（快速处理）之间的平衡。

### Lexeme, Token, Pattern and Regular expression

![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202504081232775.webp)

### 词素集合 Sets of Lexemes

将一组 Lexeme 关联到一个 Token，如：

- 将数字 token 关联到一个数字集合
- 将字符串 token 关联到一个 字符集合`{a,b,c,d······}`
- 部分 token 只能关联到一个词素，如 while

由此引发了一个问题，集合中的元素可能是无限的，我们应该如何描述他们？

从 formal language 可以获得灵感：

- 使用自动机
- 使用语法
- 使用正则表达式

参考这些方法，我们可以定义字符串集合

#### 字符串集合

由两部分组成：字符表和字符串

- 字符表：由有限的符号构成，如 $\Sigma=\{0,1\},  \mathbf{A}=\{a,b,c\}$
- 字符串：基于字符表构成的有限的序列，如 $0,00,0 \ based \ on \ \Sigma=\{0,1\}$，$a,ab,aaca \ based \ on \ \mathbf{A}=\{a,b,c\}$，还有比较特殊的空字符串 $\epsilon$，注意 $\{\epsilon\} $不等于空集合

#### 正则表达式

**正则表达式** 是一类用于描述特定语言（即**正则语言**）的形式化工具，它通常能以简洁且易读的方式刻画语言的规则。更通俗地讲：它能够很好地捕捉到语言的某种特征，且简洁易读。

##### **1. 连接（Concatenation）: R1R2**

- **定义**：将 R1 和 R2 的语言按顺序连接，生成所有可能的组合。
- **示例**：
  - 设 R1 = `a`（语言：{"a"}），R2 = `b`（语言：{"b"}），则 R1R2 = `ab`（语言：{"ab"}）。
  - 若 R1 = `a*`（任意数量的 `a`），R2 = `b`，则 R1R2 = `a*b`（如 `b`, `ab`, `aab`, ...）。

##### **2. 并集（Union）: R1 | R2**

- **定义**：匹配 R1 **或** R2 的语言。
- **示例**：
  - R1 = `cat`，R2 = `dog`，则 R1 | R2 = `cat|dog`（匹配 "cat" 或 "dog"）。
  - 在编程中常用 `|` 表示逻辑“或”（如正则表达式中的 `(a|b)`）。

##### **3. 克林闭包（Kleene Closure）: R\***

- **定义**：匹配 R 的 **0 次或多次重复**。
- **示例**：
  - R = `a`，则 R* = `a*`（语言：{ε, "a", "aa", "aaa", ...}，其中 ε 表示空字符串）。
  - 若 R = `ab`，则 R* = `(ab)*`（如 ε, "ab", "abab", ...）。

##### **4. 分组（Parentheses）: (R)**

- **定义**：括号用于明确运算优先级，不改变语义。
- **示例**：
  - `a|bc` 表示 "a" 或 "bc"，而 `(a|b)c` 表示 "ac" 或 "bc"。
  - 克林闭包中常用分组：`(ab)*` 与 `a(b*)` 不同（前者重复 "ab"，后者重复 "b"）。

---

##### **正则表达式运算优先级**

1. **克林闭包（`*`）** 优先级最高，如 `ab*` 表示 `a(b*)`。
2. **连接（R1R2）** 次之，如 `a|bc` 表示 `a` 或 `bc`。
3. **并集（`|`）** 优先级最低，需用括号明确逻辑，如 `(a|b)c`。

---

##### **实际应用场景**

- **词法分析器（Lexer）**：用正则表达式定义 Token 的规则。
  - 例如：标识符 = `[a-zA-Z_][a-zA-Z0-9_]*`（连接 + 克林闭包）。
- **字符串搜索**：如匹配邮箱 `\w+@\w+\.\w+`（连接 + 字符类）。

通过组合这些基本操作，可以构建复杂的正则表达式，描述绝大多数**正则语言**的规则。

##### **常见缩写形式（Shorthands）**

正则表达式提供了一些**缩写符号**（Shorthands），用于简化常见模式的书写。这些缩写通常以反斜杠 `\` 开头，表示特定的字符类或特殊匹配规则。以下是常见的缩写形式及其解释：

---

###### **1. 预定义字符类（Predefined Character Classes）**

| 缩写 | 等价形式         | 说明                                            |
| ---- | ---------------- | ----------------------------------------------- |
| `\d` | `[0-9]`          | **数字**（Digit）                               |
| `\D` | `[^0-9]`         | **非数字**                                      |
| `\w` | `[a-zA-Z0-9_]`   | **单词字符**（Word，含字母、数字、下划线）      |
| `\W` | `[^a-zA-Z0-9_]`  | **非单词字符**                                  |
| `\s` | `[ \t\n\r\f\v]`  | **空白字符**（Space，包括空格、制表符、换行等） |
| `\S` | `[^ \t\n\r\f\v]` | **非空白字符**                                  |

**示例：**

- `\d+` 匹配 **1 个或多个数字**（如 `123`）。
- `\w{3}` 匹配 **3 个字母/数字/下划线**（如 `abc`、`A_1`）。
- `\s+` 匹配 **1 个或多个空白字符**（如 ` `、`\t\t`）。

---

###### **2. 边界匹配（Boundary Assertions）**

| 缩写 | 说明                                                     |
| ---- | -------------------------------------------------------- |
| `\b` | **单词边界**（如 `\bword\b` 匹配独立的 "word"）          |
| `\B` | **非单词边界**（如 `\Bword\B` 匹配 "sword" 中的 "word"） |
| `^`  | **行首**（如 `^Hello` 匹配行首的 "Hello"）               |
| `$`  | **行尾**（如 `end$` 匹配行尾的 "end"）                   |

**示例：**

- `\bcat\b` 匹配 "a cat" 中的 "cat"，但不匹配 "category"。
- `^[A-Z]` 匹配 **行首的大写字母**（如 "Hello" 的 "H"）。

---

###### **3. 量词缩写（Quantifier Shorthands）**

| 缩写 | 等价形式 | 说明                       |
| ---- | -------- | -------------------------- |
| `?`  | `{0,1}`  | **0 次或 1 次**（可选）    |
| `*`  | `{0,}`   | **0 次或多次**（克林闭包） |
| `+`  | `{1,}`   | **1 次或多次**（至少一次） |

**示例：**

- `colou?r` 匹配 "color" 或 "colour"（`u` 是可选的）。
- `a+` 匹配 **1 个或多个 `a`**（如 `a`, `aa`, `aaa`）。
- `.*` 匹配 **任意字符（除换行外）任意次数**（常用于通配）。

---

###### **4. 特殊字符转义（Escaped Characters）**

某些字符在正则中有特殊含义（如 `.`、`*`、`?`），如果想匹配它们本身，需要用 `\` 转义：

| 缩写 | 实际匹配的字符 |
| ---- | -------------- |
| `\.` | `.`            |
| `\*` | `*`            |
| `\?` | `?`            |
| `\\` | `\`            |

**示例：**

- `a\.txt` 匹配 **"a.txt"**（而不是 `atxt`）。
- `1\+1=2` 匹配 **"1+1=2"**（`+` 是量词，需转义）。

---

###### **5. 其他常见缩写**

| 缩写     | 说明                                   |
| -------- | -------------------------------------- |
| `\n`     | **换行符**（ASCII 0x0A）               |
| `\r`     | **回车符**（ASCII 0x0D）               |
| `\t`     | **制表符**（ASCII 0x09）               |
| `\xHH`   | **十六进制字符**（如 `\x41` 是 "A"）   |
| `\uXXXX` | **Unicode 字符**（如 `\u00A9` 是 "©"） |

**示例：**

- `\d{2}-\d{2}-\d{4}` 匹配 **日期格式**（如 `12-31-2023`）。
- `\w+@\w+\.\w{2,3}` 匹配简单**邮箱**（如 `user@mail.com`）。

---

#### 练习

假设只有字符 0 和 1：

- 请构造出一个描述字符串的、长度为四的正则表达式：`(0|1)(0|1)(0|1)(0|1)`或者 `(0|1){4}`
- 请构造出一个描述字符串的、最多含有一个 0 的正则表达式：`1*(0|epsilon)1*` 或者 `1*0?1*`

标识符：请根据标识符的规则构造标识符

- letter = [A-Za-z] 或者 letter = 'A' | 'B' | 'C' | ... | 'Z' | 'a' | ... | 'z'
- digit = [0-9]
- identifier = letter(letter | digit) \*

邮箱：已有字符表为 letter，@ 和 . 。使用 l 表示 letter，$\Sigma=\mathbf{l} \or \{.@\}$

- zhangsan@xxx.edu.cn / zhangsan.cn@163.cn：

  构造为：$\mathbf{l^+(.l^+)^*@l^{+}.l^+(.l^+)^*}$

### 有限状态机 Finite automata

正则表达式可以通过有限状态机进行实现，有限状态机可以分为两类：

- NFAs：非确定有限状态机

  - 对于一个给定的状态以及一个输入，可以有多种状态转移方式
  - 可以有 $\epsilon$ 转移

- DFAs：确定有限状态机
  - 对于每个状态每个输入，只有一种状态转移方式
  - 没有 $\epsilon$ 转移

#### 图例说明

![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202504111203616.webp)

#### NFA

1. **维护一组当前状态**，初始时为起始状态及所有通过 **ε-转移（空转移）** 可达的状态。

2. 对输入字符串的每个字符

   - 维护一个 **下一状态集合**（初始为空）。

   - 对每个当前状态：

     - 沿着所有以当前字符为标签的转移边进行跳转。
     - 将到达的状态加入下一状态集合。

   - 将所有通过 **ε-转移** 可达的状态也加入下一状态集合。

3. **时间复杂度**：若输入字符串长度为 `m`，自动机状态数为 `n`，则复杂度为 $O(mn²)$。

#### DFA

**确定性有限自动机（DFA）** 与非确定性有限自动机（NFA）类似，但有更严格的限制：

1. **每个状态对每个输入字符必须有且仅有一条转移边**（不允许“可能”或“不确定”的转移）。
2. **不允许 ε-转移**（即不允许不消耗输入字符的跳转）。
3. **时间复杂度**：若输入字符串的长度为`m`，则复杂度为 $O(m)$，与正则表达式的复杂度无关。

#### RE 转换为 NFA

将 RE 转换为 NFA 基于以下三种操作：

![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202504112203311.webp)

1. **正则表达式 → NFA 的转换：**
   - 任何长度为 `n` 的正则表达式，都可以转换为一个具有 $O(n)$ 个状态 的非确定性有限自动机（NFA）。
2. **字符串匹配的时间复杂度：**

   - 对于长度为 `m` 的字符串，检查它是否匹配长度为 `n` 的正则表达式的时间复杂度为 **$O(mn²)$**。

3. **优化展望：**
   - 后续将介绍如何将时间复杂度优化至 **O(m)**（且与正则表达式的复杂度无关！）。

#### 从 NFA 转换为 DFA

NFA 可能同时处于多个状态，而 DFA 在每个时刻，只能处于一种状态，我们的方法是让 DFA 模拟 NFA：NFA 中的一组状态对应 DFA 中的某一个状态。DFA 中状态转移，与 NFA 中的状态集合转移相对应。

从 NFA 转换到 DFA，具体细节如下：

1. 需要解决的两个传递问题：

   - 剔除 $\epsilon$，如 $S_1 \xrightarrow{\epsilon} S_2 $，$S_2$ 需要被剔除
   - 剔除从某一个状态基于单个字符的多个传递，如:

   ![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202504112350086.webp)

2. 子集构造法：DFA 中的状态对应的是原来 NFA 中的状态集合，此基于状态之间根据单个字符的传递

3. 状态集合的相关操作

   - 状态集合的 $\epsilon$ 闭包：假设现在我们有一个初始集合 $I$，基于 0 次或者更多次操作，所到达的状态，全部组合起来，构成目标状态集合 $\epsilon_{closure}(\mathbf{I})$

     ![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202504120002699.webp)

     ![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202504120001182.webp)

     如图所示，假设 $\mathbf{I}=\{0\}$，则 $\epsilon_{closure}(\mathbf{I})=\{0,1,2,4,7\}$，这些状态都是可以通过 0 次 或者多次 $\epsilon$ 传递可以到达的。

   - $\mathbf{I_a}$ 子集构造

     - $\mathbf{I}$ 是状态集合，$a$ 是字符表中的一个字符
     - $\mathbf{Move(I,a)}=\{t|s \in \mathbf{I}, and \ s \xrightarrow{a}t \}$， $\mathbf{I}$ 中所有的状态，能够通过接受字符 $a$ 到达 $t$，由此得到一个新集合
     - $\mathbf{I_a}=\epsilon_{closure}(\mathbf{Move(I,a)})$，在上一步的基础上做闭包操作
     - 上述方法相当于是做了两次运算

4. 整体算法流程：

   - 计算 $start$ 状态的 $\epsilon_{closure}$ ，得到 DFA 的开始状态
   - 在此基础上，对于每个子集/集合，基于每个字符，执行 3 中 $\mathbf{I_a}$操作
   - 直到没有新状态或者新传递
   - 标记 accepting 状态

   ![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202504120034452.webp)

   ![](https://cdn.jsdelivr.net/gh/BomLook/blog-pic@main/img/202504120034543.webp)

#### 最小化 DFA

##### **为什么需要状态最小化？**

- **减少复杂度**：最小化后的 DFA 状态数更少，匹配效率更高（O(m) 时间）。
- **避免冗余**：如编译器词法分析器中，关键词匹配的自动机需保持最简形式。

##### 目标

将状态集合划分为若干**互不相交的子集**，使得：

1. **同一子集内的状态彼此等价**（即行为完全一致）；
2. **不同子集间的状态可区分**（存在至少一个输入能导致不同输出或状态转移）。

##### 定义

**等价状态**：如果 $s$ 和 $t$ 等价，需要满足以下条件：

1. $s$ 和 $t$ 都是接受状态或者非接受状态
2. 对于字符表中的每一个字符， $s$ 和 $t$ 都能通过同一个字符到达等价的状态

##### **具体算法**

1. **初始划分**：将状态集合划分为两个子集：
   - **接受状态集**（所有终结状态）
   - **非接受状态集**（所有非终结状态）
2. **迭代检查**：对每个子集和字母表中的每个字符 `a` ，检查子集内状态是否等价：
   - 如果存在两个状态 `s` 和 `t`，它们在输入 `a` 下的转移**落入不同子集**，则称 `a` **能区分** `s` 和 `t`。
   - 此时必须按 `a` 转移的目标子集进一步拆分当前状态集。
3. **持续这一过程，直到满足以下任一条件：**
   - **所有子集仅包含单个状态**（此时原 DFA 已是最小化形式）；
   - **无法进一步划分子集**（即所有剩余子集内部状态已完全等价）。

### 冲突解决

回想一下前面的问题：

**词法分析中的挑战：当输入存在多种扫描方式时，如何选择？**

**解决方法：**

- 最长匹配：
  - 总是匹配长度最大的，且在剩余文本中的可能前缀（从左往右扫描）
  - 避免歧义
- 优先级匹配（即关键字和标识符等的优先级）

#### 实现

1. 对于每一个正则表达式，转换为 NFA
2. 并行运行所有的 NFA ，并且记录最后一次匹配的位置
3. 当所有自动机均无法继续时，报告最后一次匹配结果，并从该位置的下一个字符重新开始扫描。
4. 若多个规则同时匹配，选择**优先级最高**的规则（例如，先定义的规则优先级更高）
5. **特殊情况处理**：**无任何规则匹配时**，添加一个**兜底规则（catch-all）**，匹配任意字符并报错。
